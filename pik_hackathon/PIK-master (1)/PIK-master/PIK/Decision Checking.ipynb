{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input files:\n",
      "['flat.csv', 'price.csv', 'status.csv', 'test.csv', 'test_.csv', 'train.cd', 'train.csv', 'train2.cd', 'train_0.csv', 'train_1.csv', 'train_2.csv', 'train_3.csv', 'train_4.csv', 'train_5.csv', 'train_6.csv', 'train_7.csv', 'train_8.csv', 'train_9.csv', 'train_full.csv', 'valid_0.csv', 'valid_1.csv', 'valid_2.csv', 'valid_3.csv', 'valid_4.csv', 'valid_5.csv', 'valid_6.csv', 'valid_7.csv', 'valid_8.csv', 'valid_9.csv']\n",
      "Loading data sets...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgbm\n",
    "# import xgboost as xgb\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\"\"\" Load and process inputs \"\"\"\n",
    "input_dir = './input/'\n",
    "print('Input files:\\n{}'.format(os.listdir(input_dir)))\n",
    "print('Loading data sets...')\n",
    "\n",
    "# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if (col_type != object) & (col_type != 'datetime64[ns]'):\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def one_hot_encoder(df, nan_as_category = True, keep_columns = None, max_num_of_unique_items = 31):\n",
    "    original_columns = list(df.columns)\n",
    "    if keep_columns is None:\n",
    "        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    else:\n",
    "        categorical_columns = [col for col in df.columns if df[col].dtype == 'object' and col not in keep_columns]\n",
    "    for col in categorical_columns:\n",
    "        if len(df[col].unique()) > max_num_of_unique_items :\n",
    "            categorical_columns = list(set(categorical_columns) - set([col]))\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns\n",
    "\n",
    "def rmsle(y_true, y_pred):\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    return np.sqrt(np.mean(np.power(np.log1p(y_true + 1) - np.log1p(y_pred + 1), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prices():\n",
    "    prices = reduce_mem_usage(pd.read_csv('./input/price.csv',\n",
    "                                         encoding='cp1251',\n",
    "                                         parse_dates=['datefrom','dateto']))\n",
    "    prices.drop(['date_salestart'], axis = 1, inplace = True)\n",
    "    # prices[\"datefrom_week\"] = prices['datefrom'].dt.week\n",
    "    prices[\"datefrom_month\"] = prices['datefrom'].dt.month\n",
    "    # prices[\"dateto_week\"] = prices['dateto'].dt.week\n",
    "    prices[\"dateto_month\"] = prices['dateto'].dt.month\n",
    "    prices[\"have_price\"] = prices['pricem2'].apply(lambda x: 1 if x > 50000 else 0)\n",
    "    prices[\"not_saled\"] = prices['dateto'].apply(lambda x: 1 if x == '2100-01-01 00:00:00' else 0)\n",
    "    prices['sales_duration'] = ((prices['dateto'] - prices['datefrom'])/30).dt.days\n",
    "    prices[\"sales_duration\"] = prices['sales_duration'].apply(lambda x: x if x > 900 else 0)\n",
    "\n",
    "    # unique_df = prices.nunique()\n",
    "    # dummy_features = list(unique_df[unique_df <= 12].index)\n",
    "    # prices = pd.get_dummies(prices, columns=dummy_features, dummy_na=True)\n",
    "    # del unique_df\n",
    "    aggregations = {}\n",
    "    aggregations = {\n",
    "                'pricem2': ['min','max','mean','count'],\n",
    "#                 'datefrom_month': ['mean'],\n",
    "#                 'dateto_month': ['mean'],\n",
    "#                 'have_price': ['mean'],\n",
    "#                 'not_saled': ['mean'],\n",
    "#                 'sales_duration': ['min', 'mean'],\n",
    "            }\n",
    "\n",
    "    # for cat in dummy_features:\n",
    "    #         aggregations[cat] = ['mean', 'min', 'max']\n",
    "\n",
    "    prices_agg = prices.groupby('id_flatwork').agg(aggregations)\n",
    "    prices_agg.columns = pd.Index(['PRICES_' + e[0] + \"_\" + e[1].upper() for e in prices_agg.columns.tolist()])\n",
    "    return prices_agg\n",
    "\n",
    "def add_lags(df, feat, index='new_index_spalen', by_col='month_cnt', aggfunc=np.mean):\n",
    "    temp = pd.pivot_table(df, index=index, values=[feat], columns=by_col, aggfunc=aggfunc)\n",
    "#     temp = df.pivot(index=index, values=[feat], columns=by_col)\n",
    "    cols = [feat+'_'+by_col+'_{}'.format(j[1]) if j[1] != \"\" else j[0] for i, j in enumerate(temp.columns)]\n",
    "    temp.columns = cols\n",
    "    temp[feat+'_lag_1'] = 0\n",
    "    for row_idx in range(temp.shape[0]):\n",
    "        for idx in range(len(cols)):\n",
    "            value = temp.iloc[row_idx, -idx-2]\n",
    "            if not np.isnan(value) :\n",
    "                temp.iloc[row_idx, -1] = value\n",
    "                break\n",
    "    new_cols = [feat+'_lag_1']\n",
    "    return temp, new_cols\n",
    "\n",
    "kfold_treshholds = [(30,32), (32,34), (33,35), (34,35)]\n",
    "def get_fold_by_col(df, col, start, end):\n",
    "    df_copy = df.reset_index()\n",
    "    train_idx = df_copy[df_copy[col] <= start].index\n",
    "    valid_idx = df_copy[df_copy[col].between(start,end)].index\n",
    "    del df_copy\n",
    "    return train_idx, valid_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.hist(df.value.values, bins = 100)\n",
    "plt.title('Histogram target counts')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8726 id\n",
      "1 233 bulk_id\n",
      "2 5 spalen\n",
      "3 7025 price\n",
      "4 3792 mean_sq\n",
      "5 32 mean_fl\n",
      "6 12 month\n",
      "7 31 month_cnt\n",
      "8 3 Класс объекта\n",
      "9 29 Количество помещений\n",
      "10 2 Огорожена территория\n",
      "11 29 Площадь земельного участка\n",
      "12 2 Входные группы\n",
      "13 21 Детский сад\n",
      "14 16 Школа\n",
      "15 4 Поликлиника\n",
      "16 2 ФОК\n",
      "17 1 Спортивная площадка\n",
      "18 2 Автомойка\n",
      "19 2 Кладовые\n",
      "20 2 Колясочные\n",
      "21 3 Кондиционирование\n",
      "22 3 Вентлияция\n",
      "23 1 Лифт\n",
      "24 1 Система мусоротведения\n",
      "25 3 Видеонаблюдение\n",
      "26 2 Подземная парковка\n",
      "27 2 Двор без машин\n",
      "28 29 Машиномест\n",
      "29 128 Площадь пром. зоны в радиусе 500 м\n",
      "30 173 Площадь зеленой зоны в радиусе 500 м\n",
      "31 17 До Кремля\n",
      "32 22 До ТТК(км)\n",
      "33 17 До Садового(км)\n",
      "34 105 До большой дороги на машине(км)\n",
      "35 79 До удобной авторазвязки на машине(км)\n",
      "36 81 До метро пешком(км)\n",
      "37 79 До промки(км)\n",
      "38 95 До парка(км)\n",
      "39 92 До парка пешком(км)\n",
      "40 10 Станций метро от кольца\n",
      "41 123 Площадь двора\n",
      "42 31 Курс\n",
      "43 30 Cтавка по ипотеке\n",
      "44 30 Вклады до 1 года\n",
      "45 31 Вклады от 1 года до 3 лет\n",
      "46 30 Вклады свыше 3 лет\n",
      "47 3072 mean_sq_spalen\n",
      "48 7594 mean_sq*price\n",
      "49 501 spalen*Площадь зеленой зоны в радиусе 500 м\n",
      "50 86 spalen*month_cnt\n",
      "51 5771 mean_sq*До удобной авторазвязки на машине(км)\n",
      "52 7302 Станций метро от кольца*price\n",
      "53 7596 price-*-mean_sq*price\n",
      "54 7369 price-*-Станций метро от кольца*price\n",
      "55 7596 mean_sq*price-*-Станций метро от кольца*price\n",
      "56 176 AGG_price_MEAN\n",
      "57 173 AGG_price_MAX\n",
      "58 168 AGG_price_MIN\n",
      "59 176 AGG_mean_sq_spalen_MEAN\n",
      "60 139 AGG_mean_sq_spalen_MAX\n",
      "61 128 AGG_mean_sq_spalen_MIN\n",
      "62 8475 price_diff_1\n",
      "63 8474 price_diff_2\n",
      "64 8655 price_diff_3\n",
      "65 60 AGG_price_MEAN_index__spalen_month\n",
      "66 60 AGG_mean_sq_spalen_MEAN_index__spalen_month\n",
      "67 55 AGG_mean_sq_spalen_MAX_index__spalen_month\n",
      "68 44 AGG_mean_sq_spalen_MIN_index__spalen_month\n",
      "69 60 AGG_mean_sq_spalen_VAR\n",
      "70 30 AGG_month_cnt_MIN\n",
      "71 2 flag_sales_started\n",
      "72 50 sales_month_cnt\n",
      "73 1 AGG_Машиномест_MIN\n",
      "74 1 AGG_Машиномест_MAX\n",
      "75 12 AGG_Машиномест_MEAN\n",
      "76 738 price_lag_1\n",
      "77 688 mean_sq_lag_1\n",
      "78 31 Курс_ratio\n",
      "79 20 FLATS_sp_stage_number_MAX\n",
      "80 489 FLATS_sp_stage_number_MEAN\n",
      "81 260 FLATS_sp_spalen_COUNT\n",
      "82 295 FLATS_sp_spalen_SUM\n",
      "83 711 FLATS_sp_square_SUM\n",
      "84 612 FLATS_sp_square_MEAN\n",
      "85 8 bulk_id_5\n",
      "86 36 AGG_price_MEAN_index_spalen_bulk_id_5\n",
      "87 36 AGG_price_MAX_index_spalen_bulk_id_5\n",
      "88 35 AGG_price_MIN_index_spalen_bulk_id_5\n",
      "89 36 AGG_price_VAR\n",
      "90 36 AGG_mean_sq_spalen_MEAN_index_spalen_bulk_id_5\n",
      "91 36 AGG_mean_sq_spalen_MAX_index_spalen_bulk_id_5\n",
      "92 35 AGG_mean_sq_spalen_MIN_index_spalen_bulk_id_5\n",
      "93 8524 mean_sq_spalen_diff_1\n",
      "94 8430 mean_sq_spalen_diff_2\n",
      "95 8661 mean_sq_spalen_diff_3\n",
      "96 15 AGG_start_square_MEAN\n",
      "97 15 AGG_start_square_MAX\n",
      "98 15 AGG_start_square_MIN\n",
      "99 15 AGG_start_square_VAR\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for col in df_train.columns.tolist():\n",
    "    print(idx, len(df_train[col].unique()), col)\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in range(num_seeds):\n",
    "    for fold in range(n_folds):\n",
    "        iter_num += 1\n",
    "        df_train = pd.read_csv('./input/train_{}.csv'.format(fold))\n",
    "        df_valid = pd.read_csv('./input/valid_{}.csv'.format(fold))\n",
    "        target_train = df_train.pop('value')\n",
    "        target_valid = df_valid.pop('value')\n",
    "        df_meta = pd.read_csv(\"./output/oof_lgbm_{}.csv\".format(fold), columns=['id','value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\lightgbm\\basic.py:1040: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\lightgbm\\basic.py:661: UserWarning: silent keyword has been found in `params` and will be ignored. Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\lightgbm\\basic.py:685: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[263]\ttrain's rmse: 262.263\tvalid's rmse: 216.666\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1477]\ttrain's rmse: 146.227\tvalid's rmse: 204.498\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7158]\ttrain's rmse: 65.129\tvalid's rmse: 246.94\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2335]\ttrain's rmse: 124.272\tvalid's rmse: 265.343\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1880]\ttrain's rmse: 137.804\tvalid's rmse: 221.118\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[821]\ttrain's rmse: 182.992\tvalid's rmse: 233.093\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[714]\ttrain's rmse: 192.022\tvalid's rmse: 229.687\n",
      "Score 230.99610155827781\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "iter_num = 0\n",
    "n_folds = 7\n",
    "avg_score = 0\n",
    "feature_importance_df = pd.DataFrame()\n",
    "df_train = pd.read_csv('./input/train_full.csv', encoding='cp1251')\n",
    "# df_train.to_csv('./input/train_full_lgbm.csv', encoding='cp1251')\n",
    "# df_oof = np.zeros((len(df), n_folds))\n",
    "# df_meta = pd.read_csv('submission_catboost_211.43605189630915_199_05136.csv')\n",
    "df_test = pd.read_csv('./input/test_.csv')\n",
    "\n",
    "# df_test['metafeature_catboost'] = df_meta['value']\n",
    "test = np.zeros((len(df_test), 1))\n",
    "oof = np.zeros((len(df_train), 1))\n",
    "num_seeds = 1\n",
    "for s in range(num_seeds):\n",
    "    for fold in range(n_folds):\n",
    "        iter_num += 1\n",
    "        df_train = pd.read_csv('./input/train_month_folds_{}.csv'.format(fold))\n",
    "        df_valid = pd.read_csv('./input/valid_month_folds_{}.csv'.format(fold))\n",
    "        target_train = df_train.pop('value')\n",
    "        target_valid = df_valid.pop('value')\n",
    "\n",
    "        discard_feats = ['id','bulk_id','date1','bulk_id_5']\n",
    "\n",
    "        cat_feats = ['spalen', 'month', 'Класс объекта',\n",
    "         'Огорожена территория', 'Входные группы', 'Детский сад', 'Школа',\n",
    "         'Поликлиника', 'ФОК', 'Спортивная площадка', 'Автомойка',\n",
    "         'Кладовые', 'Колясочные', 'Кондиционирование', 'Вентлияция',\n",
    "         'Лифт', 'Система мусоротведения', 'Видеонаблюдение', 'Подземная парковка',\n",
    "         'Двор без машин', 'flag_sales_started']\n",
    "\n",
    "        feats = [f for f in df_train.columns.tolist() if f not in discard_feats]\n",
    "    #     feats = [f for f in feats if f not in cat_feats]\n",
    "\n",
    "        lgtrain = lgb.Dataset(df_train[feats], target_train,\n",
    "                            feature_name=feats,\n",
    "                            categorical_feature = cat_feats\n",
    "                             )\n",
    "        lgvalid = lgb.Dataset(df_valid[feats], target_valid,\n",
    "                            feature_name=feats,\n",
    "                            categorical_feature = cat_feats\n",
    "                             )\n",
    "\n",
    "        lgbm_params =  {\n",
    "            'task': 'train',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            # 'max_depth': 15,\n",
    "            'num_leaves': 34,\n",
    "            'nthread':4,\n",
    "            'learning_rate': 0.005,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'subsample': 0.87,\n",
    "            'max_depth': -1,\n",
    "            'reg_alpha': 0.04,\n",
    "            'min_split_gain': 0.017,\n",
    "            'min_child_weight': 20,\n",
    "            'verbose': -1,\n",
    "            'silent':-1,\n",
    "            'seed':s,\n",
    "            'random_state':s\n",
    "        }\n",
    "\n",
    "        lgb_clf = lgb.train(\n",
    "                lgbm_params,\n",
    "                lgtrain,\n",
    "                num_boost_round=10000,\n",
    "                valid_sets=[lgtrain, lgvalid],\n",
    "                valid_names=['train','valid'],\n",
    "                early_stopping_rounds=300,\n",
    "                verbose_eval=10000\n",
    "            )\n",
    "        # print('RMSE:', np.sqrt(mean_squared_error(target_valid, lgb_clf.predict(df_valid[feats]))))\n",
    "        pred = lgb_clf.predict(df_test[feats])\n",
    "        test += pred.reshape((len(df_test),1))\n",
    "        df_test['value'] = pred\n",
    "        df_test.to_csv(\"./output/test_lgbm_m_{}.csv.\".format(fold), index=False, columns=['id','value'])\n",
    "        pred = lgb_clf.predict(df_valid[feats])\n",
    "        df = pd.read_csv(\"./input/valid_month_folds_{}.csv.\".format(fold))\n",
    "        oof[df.id] = pred.reshape((len(df),1))\n",
    "        df['value'] = pred\n",
    "        df.to_csv(\"./output/oof_lgbm_m_{}.csv\".format(fold), index=False, columns=['id','value'])\n",
    "    #     full_train = pd.read_csv('./input/train_full_lgbm.csv', encoding='cp1251')\n",
    "    #     full_train['oof_'.format(fold)] = pred\n",
    "    #     full_train.to_csv('./input/train_full_lgbm.csv', encoding='cp1251')\n",
    "    #     oof_score = model.score(val_pool, oof_value)\n",
    "    #     print('Iteration {} with oof score {}'.format(i, oof_score))\n",
    "        oof_score = mean_squared_error(target_valid, pred)**0.5\n",
    "        avg_score += oof_score\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = lgb_clf.feature_importance\n",
    "        fold_importance_df[\"fold\"] = fold + 1\n",
    "        fold_importance_df[\"seed\"] = s\n",
    "        fold_importance_df['oof_score'] = oof_score\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "df = pd.read_csv('./input/sample submission.csv', encoding='cp1251')\n",
    "\n",
    "df['value'] = (test/iter_num).clip(0, 3000)\n",
    "df.to_csv('submission_lgbm_m_'+str(avg_score/(iter_num))+'.csv', index=False)\n",
    "print('Score {}'.format(avg_score/iter_num))\n",
    "# df = pd.read_csv(path+\"train_full.csv\", encoding='cp1251')\n",
    "# df['value_pred'] = oof\n",
    "# df.to_csv('./output/oof_'+str(avg_score/(i+1))+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1770"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lgb_clf.predict(df_test[feats]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=100, shuffle=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\lightgbm\\basic.py:1040: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\lightgbm\\basic.py:661: UserWarning: silent keyword has been found in `params` and will be ignored. Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\lightgbm\\basic.py:685: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[220]\ttrain's rmse: 190.315\tvalid's rmse: 212.598\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[248]\ttrain's rmse: 186.064\tvalid's rmse: 211.116\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[325]\ttrain's rmse: 178.072\tvalid's rmse: 200.056\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[724]\ttrain's rmse: 150.835\tvalid's rmse: 216.286\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[158]\ttrain's rmse: 201.183\tvalid's rmse: 223.671\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4259]\ttrain's rmse: 66.5025\tvalid's rmse: 204.342\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[731]\ttrain's rmse: 149.796\tvalid's rmse: 252.391\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[230]\ttrain's rmse: 188.385\tvalid's rmse: 211.04\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[499]\ttrain's rmse: 161.381\tvalid's rmse: 246.447\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[232]\ttrain's rmse: 187.398\tvalid's rmse: 207.706\n",
      "Score 218.56529805126252\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "df_stack_meta1 = pd.DataFrame()\n",
    "df_stack_meta2 = pd.DataFrame()\n",
    "\n",
    "for i in range(10):\n",
    "    df = pd.read_csv('./output/oof_{}.csv'.format(i))\n",
    "    val = df['value']\n",
    "    df_stack_meta1 = pd.concat([df_stack_meta1, df])\n",
    "\n",
    "    df = pd.read_csv('./output/oof_lgbm_{}.csv'.format(i))\n",
    "    val = df['value']\n",
    "    df_stack_meta2 = pd.concat([df_stack_meta2, df])\n",
    "df_stack_meta1 = df_stack_meta1.sort_values(['id']).set_index(['id'])\n",
    "df_stack_meta2 = df_stack_meta2.sort_values(['id']).set_index(['id'])\n",
    "\n",
    "K = 10\n",
    "df = pd.read_csv(\"./input/train_full.csv\")\n",
    "df['metafeature_catboost'] = df_stack_meta1['value']\n",
    "df['metafeature_lgbm'] = df_stack_meta2['value']\n",
    "\n",
    "df_test = pd.read_csv('./input/test_.csv')\n",
    "df_stack_meta1 = pd.read_csv('submission_catboost_212.64175801420384_198.csv')\n",
    "df_stack_meta2 = pd.read_csv('submission_lgbm_207.2784140815164_205_224.csv')\n",
    "df_test['metafeature_catboost'] = df_stack_meta1['value']\n",
    "df_test['metafeature_lgbm'] = df_stack_meta2['value']\n",
    "\n",
    "kf = KFold(n_splits=K, random_state=100, shuffle=True)\n",
    "kf.get_n_splits(range(len(df)))\n",
    "\n",
    "print(kf)  \n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(kf.split(range(len(df)))):\n",
    "    train = df.loc[train_index]\n",
    "    valid = df.loc[valid_index]\n",
    "\n",
    "    train.to_csv(f\"./input/train_meta_cb_{i}.csv\",index=False)\n",
    "    valid.to_csv(f\"./input/valid_meta_cb_{i}.csv\",index=False)\n",
    "\n",
    "df_test.to_csv('./input/test_meta.csv',index=False)\n",
    "    \n",
    "iter_num = 0\n",
    "n_folds = 10\n",
    "avg_score = 0\n",
    "feature_importance_df = pd.DataFrame()\n",
    "df_train = pd.read_csv('./input/train_full.csv', encoding='cp1251')\n",
    "# df_train.to_csv('./input/train_full_lgbm.csv', encoding='cp1251')\n",
    "# df_oof = np.zeros((len(df), n_folds))\n",
    "# df_meta = pd.read_csv('submission_catboost_211.43605189630915_199_05136.csv')\n",
    "# df_test = pd.read_csv('./input/test_.csv')\n",
    "\n",
    "# df_test['metafeature_catboost'] = df_meta['value']\n",
    "test = np.zeros((len(df_test), 1))\n",
    "oof = np.zeros((len(df_train), 1))\n",
    "num_seeds = 1\n",
    "for s in range(num_seeds):\n",
    "    for fold in range(n_folds):\n",
    "        iter_num += 1\n",
    "        df_train = pd.read_csv('./input/train_meta_cb_{}.csv'.format(fold))\n",
    "        df_valid = pd.read_csv('./input/valid_meta_cb_{}.csv'.format(fold))\n",
    "        target_train = df_train.pop('value')\n",
    "        target_valid = df_valid.pop('value')\n",
    "\n",
    "        discard_feats = ['id','bulk_id','date1','bulk_id_5']\n",
    "\n",
    "        cat_feats = ['spalen', 'month', 'Класс объекта',\n",
    "         'Огорожена территория', 'Входные группы', 'Детский сад', 'Школа',\n",
    "         'Поликлиника', 'ФОК', 'Спортивная площадка', 'Автомойка',\n",
    "         'Кладовые', 'Колясочные', 'Кондиционирование', 'Вентлияция',\n",
    "         'Лифт', 'Система мусоротведения', 'Видеонаблюдение', 'Подземная парковка',\n",
    "         'Двор без машин', 'flag_sales_started']\n",
    "\n",
    "        feats = [f for f in df_train.columns.tolist() if f not in discard_feats]\n",
    "#         feats = ['metafeature_catboost','metafeature_lgbm']\n",
    "\n",
    "        lgtrain = lgb.Dataset(df_train[feats], target_train,\n",
    "                            feature_name=feats,\n",
    "                            categorical_feature = cat_feats\n",
    "                             )\n",
    "        lgvalid = lgb.Dataset(df_valid[feats], target_valid,\n",
    "                            feature_name=feats,\n",
    "                            categorical_feature = cat_feats\n",
    "                             )\n",
    "\n",
    "        lgbm_params =  {\n",
    "            'task': 'train',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            # 'max_depth': 15,\n",
    "            'num_leaves': 34,\n",
    "            'nthread':4,\n",
    "            'learning_rate': 0.01,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'subsample': 0.87,\n",
    "            'max_depth': -1,\n",
    "            'reg_alpha': 0.04,\n",
    "            'min_split_gain': 0.017,\n",
    "            'min_child_weight': 20,\n",
    "            'verbose': -1,\n",
    "            'silent':-1,\n",
    "            'seed':s,\n",
    "            'random_state':s\n",
    "        }\n",
    "\n",
    "        lgb_clf = lgb.train(\n",
    "                lgbm_params,\n",
    "                lgtrain,\n",
    "                num_boost_round=10000,\n",
    "                valid_sets=[lgtrain, lgvalid],\n",
    "                valid_names=['train','valid'],\n",
    "                early_stopping_rounds=300,\n",
    "                verbose_eval=10000\n",
    "            )\n",
    "        # print('RMSE:', np.sqrt(mean_squared_error(target_valid, lgb_clf.predict(df_valid[feats]))))\n",
    "        pred = lgb_clf.predict(df_test[feats])\n",
    "        test += pred.reshape((len(df_test),1))\n",
    "        df_test['value'] = pred\n",
    "#         df_test.to_csv(\"./output/test_lgbm_{}.csv.\".format(fold), index=False, columns=['id','value'])\n",
    "        pred = lgb_clf.predict(df_valid[feats])\n",
    "        df = pd.read_csv(\"./output/oof_{}.csv.\".format(fold))\n",
    "        oof[df.id] = pred.reshape((len(df),1))\n",
    "        df['value'] = pred\n",
    "#         df.to_csv(\"./output/oof_lgbm_{}.csv\".format(fold), index=False, columns=['id','value'])\n",
    "    #     full_train = pd.read_csv('./input/train_full_lgbm.csv', encoding='cp1251')\n",
    "    #     full_train['oof_'.format(fold)] = pred\n",
    "    #     full_train.to_csv('./input/train_full_lgbm.csv', encoding='cp1251')\n",
    "    #     oof_score = model.score(val_pool, oof_value)\n",
    "    #     print('Iteration {} with oof score {}'.format(i, oof_score))\n",
    "        oof_score = mean_squared_error(target_valid, pred)**0.5\n",
    "        avg_score += oof_score\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = lgb_clf.feature_importance\n",
    "        fold_importance_df[\"fold\"] = fold + 1\n",
    "        fold_importance_df[\"seed\"] = s\n",
    "        fold_importance_df['oof_score'] = oof_score\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "df = pd.read_csv('./input/sample submission.csv', encoding='cp1251')\n",
    "\n",
    "df['value'] = (test/iter_num).clip(0, 3000)\n",
    "df.to_csv('submission_lgbm_meta_'+str(avg_score/(iter_num))+'.csv', index=False)\n",
    "print('Score {}'.format(avg_score/iter_num))\n",
    "# df = pd.read_csv(path+\"train_full.csv\", encoding='cp1251')\n",
    "# df['value_pred'] = oof\n",
    "# df.to_csv('./output/oof_'+str(avg_score/(i+1))+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stack_meta1 = pd.read_csv('submission_catboost_212.64175801420384_198.csv')\n",
    "df_stack_meta2 = pd.read_csv('submission_lgbm_207.2784140815164_205_224.csv')\n",
    "sub = df_stack_meta1\n",
    "sub['value'] = (df_stack_meta1['value'] + df_stack_meta2['value'])/2\n",
    "sub.to_csv('sub_ans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./output/test_0.csv')\n",
    "pred = np.zeros((len(df), ))\n",
    "\n",
    "for i in [0,2,3,4,5]:\n",
    "    if i != 6:\n",
    "        df = pd.read_csv('./output/test_{}.csv'.format(i))\n",
    "        val = df['value']\n",
    "        pred += val\n",
    "    \n",
    "df = pd.read_csv(\"./input/sample submission.csv\", encoding='cp1251')\n",
    "df['value'] = (pred/9).clip(0, 5000)\n",
    "df.to_csv('submission_catboost_5_folds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:188: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting LightGBM. Train shape: (8726, 80), test shape: (1770, 81)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5682]\ttraining's rmse: 73.5159\tvalid_1's rmse: 222.74\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5822]\ttraining's rmse: 73.7339\tvalid_1's rmse: 184.692\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[9143]\ttraining's rmse: 51.6095\tvalid_1's rmse: 218.562\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8424]\ttraining's rmse: 56.3467\tvalid_1's rmse: 216.179\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3734]\ttraining's rmse: 94.4016\tvalid_1's rmse: 234.64\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4764]\ttraining's rmse: 83.1131\tvalid_1's rmse: 234.966\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4762]\ttraining's rmse: 83.2178\tvalid_1's rmse: 199.491\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3004]\ttraining's rmse: 105.996\tvalid_1's rmse: 185.996\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2994]\ttraining's rmse: 104.229\tvalid_1's rmse: 206.559\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8311]\ttraining's rmse: 56.551\tvalid_1's rmse: 189.365\n",
      "209.31896147870376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = get_df_for_submit()\n",
    "target_column = 'value'\n",
    "\n",
    "train_df = df[df[target_column].notnull()]\n",
    "test_df = df[df[target_column].isnull()]\n",
    "\n",
    "num_folds = 10\n",
    "nseeds = 1\n",
    "target = train_df.pop(target_column)\n",
    "# target = np.log1p(target)\n",
    "\n",
    "feats = train_df.columns.tolist()\n",
    "print(\"\\nStarting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "gc.collect()\n",
    "    # Cross validation model\n",
    "folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "    # Create arrays and dataframes to store results\n",
    "oof_preds = np.zeros(train_df.shape[0])\n",
    "sub_preds = np.zeros(test_df.shape[0])\n",
    "feature_importance_df = pd.DataFrame()\n",
    "avg_score = 0\n",
    "run_times = 0\n",
    "\n",
    "discard_columns = ['bulk_id', 'bulk_id_1', 'bulk_id_2', 'bulk_id_3', 'bulk_id_4','new_index_unique',\n",
    "                       'new_index_unique_lag_1','new_index_unique_lag_2','new_index_unique_lag_3',\n",
    "                       'new_index_unique_lag_4','new_index_unique_lag_5','new_index_unique_lag_6',\n",
    "                       'new_index_spalen','Курс', 'end_square', 'bulk_id_5', target_column, 'date1']\n",
    "\n",
    "feats = list(set(list(feats)) - set(discard_columns))\n",
    "# feats = list(set(list(feats)) - set(not_important_features))\n",
    "\n",
    "    # feats = list(train_df.columns)\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], target)):\n",
    "    train_x, train_y = train_df[feats].iloc[train_idx], target.iloc[train_idx]\n",
    "    valid_x, valid_y = train_df[feats].iloc[valid_idx], target.iloc[valid_idx]\n",
    "    nseeds = nseeds\n",
    "    for s in range(nseeds):\n",
    "        test_df_clear = test_df.copy()\n",
    "        run_times += 1\n",
    "            # LightGBM parameters found by Bayesian optimization\n",
    "        clf = LGBMRegressor(\n",
    "    #                     boosting = 'dart',\n",
    "#                         device_type='gpu',\n",
    "                        nthread=4,\n",
    "                        n_estimators=10000,\n",
    "                        learning_rate=0.01,\n",
    "                        num_leaves=34,\n",
    "                        colsample_bytree=0.8,\n",
    "                        subsample=0.87,\n",
    "                        max_depth=-1,\n",
    "                        reg_alpha=0.041545473,\n",
    "                        reg_lambda=0.0735294,\n",
    "                        min_split_gain=0.017,\n",
    "                        min_child_weight=20,\n",
    "                        silent=-1,\n",
    "                        verbose=-1, \n",
    "                        seed=s,\n",
    "                        random_state=s)\n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "                            eval_metric= 'rmse', verbose= 15000, early_stopping_rounds= 300)\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict(valid_x, num_iteration=clf.best_iteration_)\n",
    "#         oof_preds[valid_idx] = np.expm1(oof_preds[valid_idx])\n",
    "        y_pred = clf.predict(test_df_clear[feats], num_iteration=clf.best_iteration_)\n",
    "#         y_pred = np.expm1(y_pred)\n",
    "    #         test_df_clear[target_column] = y_pred\n",
    "\n",
    "    #         temp, new_cols = add_lags(test_df_clear, feat='value', index='new_index_spalen', by_col='month_cnt')\n",
    "    #         test_df_clear.drop(new_cols, inplace=True, axis=1)\n",
    "    #         test_df_clear = test_df_clear.merge(temp[new_cols], on='new_index_spalen',  how='left')\n",
    "    #         y_pred = clf.predict(test_df_clear[feats], num_iteration=clf.best_iteration_)\n",
    "\n",
    "        sub_preds +=  pd.Series(y_pred).values #/ folds.n_splits\n",
    "        test_df_clear['value'] = sub_preds\n",
    "        test_df_clear.to_csv('test_'+str(run_times)+'.csv')\n",
    "        oof_score = mean_squared_error(valid_y, oof_preds[valid_idx])**0.5\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        fold_importance_df[\"seed\"] = s\n",
    "        fold_importance_df['oof_score'] = oof_score\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "            # print('Fold %2d Seed %i AUC : %.6f' % (n_fold + 1, s, score))\n",
    "        avg_score +=  oof_score\n",
    "    #del clf, train_x, train_y, valid_x, valid_y\n",
    "gc.collect()\n",
    "\n",
    "print(avg_score/run_times)\n",
    "test_df['value'] = np.clip(sub_preds/run_times, 0, None)\n",
    "test_df['id'] = list(range(len(test_df)))\n",
    "test_df[['id','value']].to_csv('submission_v2_'+str(avg_score/run_times)+'_.csv', index=False)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.hist(test_df['value'], bins = 100)\n",
    "plt.title('Predictions')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Target')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(param):\n",
    "    df = pd.read_csv(os.path.join(input_dir,'train.csv'), parse_dates=['date1'], encoding='cp1251')\n",
    "    df_test = pd.read_csv(os.path.join(input_dir,'test.csv'), parse_dates=['date1'], encoding='cp1251')\n",
    "    absent_columns = list(set(df.columns) - set(list(df_test.columns))-set(['value']))\n",
    "    df.drop(absent_columns, axis=1, inplace=True)\n",
    "    \n",
    "#     df = df[df.value > 0]\n",
    "#     df.value = np.log1p(df.value)\n",
    "#     df['value'] = np.clip(df['value'],0,1500)\n",
    "#     df['value'] = np.round(df['value']* df['price'],decimals=0)\n",
    "#     df=df[df.spalen == param]\n",
    "    \n",
    "    test_df = df[df.month_cnt >= 35]\n",
    "    test_target = test_df['value']\n",
    "    test_df['value'] = 0\n",
    "    train_df = df[df.month_cnt <= 34]\n",
    "#     train_df = train_df[train_df.month_cnt >= param]\n",
    "#     train_df = train_df[train_df.value > 0]\n",
    "    train_df['value'] = np.clip(train_df['value'],0,5000)\n",
    "    \n",
    "    df = pd.concat([train_df,test_df])\n",
    "    \n",
    "    df['mean_sq_spalen'] = df['mean_sq'] / (df['spalen']+1)\n",
    "    df['mean_sq*price'] = df['mean_sq']*df['price'] ## 220.94\n",
    "    df['spalen*Площадь зеленой зоны в радиусе 500 м'] = df['spalen']*df['Площадь зеленой зоны в радиусе 500 м'] ## 220,04\n",
    "    df['spalen*month_cnt'] = df['spalen']*df['month_cnt'] ## 219.77\n",
    "    df['mean_sq*До удобной авторазвязки на машине(км)'] = df['mean_sq']*df['До удобной авторазвязки на машине(км)'] ## 219.78\n",
    "    df['Станций метро от кольца*price'] = df['Станций метро от кольца']*df['price'] ## 219.19\n",
    "    \n",
    "    \n",
    "    df['price-*-mean_sq*price'] = df['price']*df['mean_sq*price']\n",
    "    df['price-*-Станций метро от кольца*price'] = df['price']*df['Станций метро от кольца*price']\n",
    "    df['mean_sq*price-*-Станций метро от кольца*price'] = df['mean_sq*price']*df['Станций метро от кольца*price']\n",
    "    \n",
    "    \n",
    "    \n",
    "    df['new_index_spalen'] = df['bulk_id'] + '-' + df['spalen'].astype(str)\n",
    "#     df['new_index_unique'] = df['bulk_id'] + '-' + df['spalen'].astype(str) + '_' + df['month_cnt'].astype(str)\n",
    "#     df['new_index_unique_lag_1'] = df['bulk_id'] + '-' + df['spalen'].astype(str) + '_' + (df['month_cnt']+1).astype(str)\n",
    "#     df['new_index_unique_lag_2'] = df['bulk_id'] + '-' + df['spalen'].astype(str) + '_' + (df['month_cnt']+2).astype(str)\n",
    "#     df['new_index_unique_lag_3'] = df['bulk_id'] + '-' + df['spalen'].astype(str) + '_' + (df['month_cnt']+3).astype(str)\n",
    "#     df['new_index_unique_lag_4'] = df['bulk_id'] + '-' + df['spalen'].astype(str) + '_' + (df['month_cnt']+4).astype(str)\n",
    "#     df['new_index_unique_lag_5'] = df['bulk_id'] + '-' + df['spalen'].astype(str) + '_' + (df['month_cnt']+5).astype(str)\n",
    "#     df['new_index_unique_lag_6'] = df['bulk_id'] + '-' + df['spalen'].astype(str) + '_' + (df['month_cnt']+6).astype(str)\n",
    "\n",
    "\n",
    "    #temp = df.pivot(index='new_index_spalen', values=[\"price\"], columns=\"month_cnt\")\n",
    "    #temp.columns = [\"value_lag_{}\".format(i)  if j[1] != \"\" else j[0] for i, j in enumerate(temp.columns)]\n",
    "    #df = df.merge(temp, on='new_index_spalen',  how='left')\n",
    "    \n",
    "    #temp = df.pivot(index='new_index_spalen', values=[\"mean_sq\"], columns=\"month_cnt\")\n",
    "    #temp.columns = [\"value_lag_{}\".format(i)  if j[1] != \"\" else j[0] for i, j in enumerate(temp.columns)]\n",
    "    #df = df.merge(temp, on='new_index_spalen',  how='left')\n",
    "    \n",
    "    \n",
    "    #temp, new_cols = add_lags(df, feat='value', index='new_index_spalen', by_col='month_cnt')\n",
    "    #df = df.merge(temp[new_cols], on='new_index_spalen',  how='left')\n",
    "    \n",
    "    #temp, new_cols = add_lags(df, feat='price', index='new_index_spalen', by_col='month_cnt')\n",
    "    #df = df.merge(temp[new_cols], on='new_index_spalen',  how='left')\n",
    "    \n",
    "    #temp, new_cols = add_lags(df, feat='mean_sq', index='new_index_spalen', by_col='month_cnt')\n",
    "    #df = df.merge(temp[new_cols], on='new_index_spalen',  how='left')\n",
    "    \n",
    "    ###\n",
    "    flats = get_flats(df)\n",
    "    flats_cols = list(flats.columns)\n",
    "    print(\"Flats df shape:\", flats.shape)\n",
    "    df = df.join(flats, how='left', on='new_index_spalen')\n",
    "    del flats\n",
    "    gc.collect() ##220\n",
    "\n",
    "#     df_bulk_cols = ['bulk_id_1','bulk_id_2','bulk_id_3','bulk_id_4','bulk_id_5']\n",
    "#     df_bulk = pd.DataFrame(df.bulk_id.str.split('-').values.tolist(), columns=df_bulk_cols\n",
    "#                            , index=df.index)\n",
    "#     df[df_bulk_cols] = df_bulk[df_bulk_cols]\n",
    "    \n",
    "#     df['mean_sq*price'] = df['mean_sq']*df['price'] ## 220.94\n",
    "#     df['spalen*Площадь зеленой зоны в радиусе 500 м'] = df['spalen']*df['Площадь зеленой зоны в радиусе 500 м'] ## 220,04\n",
    "#     df['spalen*month_cnt'] = df['spalen']*df['month_cnt'] ## 219.77\n",
    "#     df['spalen*month'] = df['spalen']*df['month']\n",
    "#     df['Станций метро от кольца*price'] = df['Станций метро от кольца']*df['price']\n",
    "    ###\n",
    "    \n",
    "#     col1 = 'Класс объекта'\n",
    "#     col2 = 'spalen'\n",
    "#     col3 = 'month'\n",
    "#     index_name = 'index_'+col1+'_'+col2+'_'+col3\n",
    "#     df[index_name] = df[col1] + '-' + df[col2].astype(str) + '-' + df[col3].astype(str)\n",
    "#     groupby_col = index_name\n",
    "#     aggregations = {\n",
    "#                 'price': ['mean','max','min'],\n",
    "#             }\n",
    "#     df_agg = df[df.value > 0].groupby([groupby_col]).agg(aggregations)\n",
    "#     df_agg.columns = pd.Index(['AGG_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "#     df = df.join(df_agg, how='left', on=groupby_col, rsuffix='_'+groupby_col)\n",
    "#     df.drop(index_name, inplace=True, axis=1)\n",
    "    \n",
    "#     df['price_diff_1'] = df['price']/df['AGG_price_MAX']\n",
    "#     df['price_diff_2'] = df['price']/df['AGG_price_MIN']\n",
    "#     df['price_diff_3'] = df['price']/df['AGG_price_MEAN']\n",
    "    \n",
    "#     col2 = 'bulk_id_5'\n",
    "#     col3 = 'month'\n",
    "#     index_name = 'index_'+'_'+col2+'_'+col3\n",
    "#     df[index_name] = df[col2].astype(str) + '-' + df[col3].astype(str)\n",
    "#     groupby_col = index_name\n",
    "#     aggregations = {\n",
    "#                 'price': ['mean'],\n",
    "#             }\n",
    "#     df_agg = df[df.value > 0].groupby([groupby_col]).agg(aggregations)\n",
    "#     df_agg.columns = pd.Index(['AGG_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "#     df = df.join(df_agg, how='left', on=groupby_col, rsuffix='_'+groupby_col)\n",
    "#     df.drop(index_name, inplace=True, axis=1)\n",
    "    \n",
    "#     groupby_col = 'bulk_id'\n",
    "#     aggregations = {\n",
    "#                 'month_cnt': ['min','max'],\n",
    "#             }\n",
    "#     df_agg = df[df.value > 0].groupby([groupby_col]).agg(aggregations)\n",
    "#     df_agg.columns = pd.Index(['AGG_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "#     df = df.join(df_agg, how='left', on=groupby_col, rsuffix='_'+groupby_col)\n",
    "#     df['flag_sales_started'] = np.where(df['month_cnt']==df['AGG_month_cnt_MIN'], 1, 0)\n",
    "\n",
    "    \n",
    "#     groupby_col = 'spalen'\n",
    "#     aggregations = {\n",
    "#                 'value': ['mean'],\n",
    "#             }\n",
    "#     df_agg = df[df.value > 0].groupby([groupby_col]).agg(aggregations)\n",
    "#     df_agg.columns = pd.Index(['AGG_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "#     df = df.join(df_agg, how='left', on=groupby_col, rsuffix='_'+groupby_col)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #     df['flag_sales_ended'] = df.apply(lambda x: 1 if x['month_cnt'] == x['AGG_month_cnt_MIN'] else 0)\n",
    "    \n",
    "#     col2 = 'spalen'\n",
    "#     col3 = 'month'\n",
    "#     index_name = 'index_'+'_'+col2+'_'+col3\n",
    "#     df[index_name] = df[col2].astype(str) + '-' + df[col3].astype(str)\n",
    "#     groupby_col = index_name\n",
    "#     aggregations = {\n",
    "#                 'value': ['mean'],\n",
    "#             }\n",
    "#     df_agg = df[df.value > 0].groupby([groupby_col]).agg(aggregations)\n",
    "#     df_agg.columns = pd.Index(['AGG_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "#     df = df.join(df_agg, how='left', on=groupby_col, rsuffix='_'+groupby_col)\n",
    "#     df.drop(index_name, inplace=True, axis=1)\n",
    "#     ##\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     temp, new_cols = add_lags(df, feat='value', index=index_name, by_col='spalen')\n",
    "#     df = df.merge(temp[new_cols], on=index_name,  how='left')\n",
    "#     df.drop(index_name, inplace=True, axis=1)\n",
    "    ###\n",
    "    \n",
    "    #############\n",
    "#     groupby_col = 'month'\n",
    "#     aggregations = {}\n",
    "#     cols = ['mean_sq*price',\n",
    "# #             'mean_sq',\n",
    "# #             'Машиномест'\n",
    "#            ]\n",
    "#     for col in cols:\n",
    "#         aggregations = {\n",
    "#                 col: ['min', 'max', 'mean'],\n",
    "#             }\n",
    "#     df_agg = df.groupby([groupby_col]).agg(aggregations)\n",
    "#     df_agg.columns = pd.Index(['AGG_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "#     df = df.join(df_agg, how='left', on=groupby_col, rsuffix='_'+groupby_col)\n",
    "    #############\n",
    "\n",
    "#     groupby_col = 'spalen*month'\n",
    "#     aggregations = {}\n",
    "#     cols = ['До парка пешком(км)',\n",
    "# #             'FLATS_otdelka_Монолит-лоукост_SUM'\n",
    "#            ]\n",
    "#     for col in cols:\n",
    "#         aggregations = {\n",
    "#                     col: ['min', 'max', 'mean'],\n",
    "#                 }\n",
    "#     df_agg = df.groupby([groupby_col]).agg(aggregations)\n",
    "#     df_agg.columns = pd.Index(['AGG_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "#     df = df.join(df_agg, how='left', on=groupby_col, rsuffix='_'+groupby_col)\n",
    "    \n",
    "    \n",
    "    #############\n",
    "    #groupby_col = 'bulk_id_1'\n",
    "    #aggregations = {}\n",
    "    #aggregations = {\n",
    "    #        'value': ['min', 'max', 'mean','var'],\n",
    "    #    }\n",
    "    #df_agg = df.groupby([groupby_col]).agg(aggregations)\n",
    "    #df_agg.columns = pd.Index(['AGG_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "    #df = df.join(df_agg, how='left', on=groupby_col, rsuffix='_'+groupby_col)\n",
    "    #############\n",
    "    \n",
    "    #############\n",
    "    #groupby_col = 'bulk_id_5'\n",
    "    #aggregations = {}\n",
    "    #aggregations = {\n",
    "    #         'price': ['mean'],\n",
    "    #     }\n",
    "    #df_agg = df.groupby([groupby_col]).agg(aggregations)\n",
    "    #df_agg.columns = pd.Index(['AGG_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "    #df = df.join(df_agg, how='left', on=groupby_col, rsuffix='_'+groupby_col)\n",
    "    #############\n",
    "    \n",
    "    #index_name = 'index_bulk_id_spalen'\n",
    "   # df[index_name] = df['bulk_id'] + '-' + df['spalen'].astype(str)\n",
    "    #temp = pd.pivot_table(df, index=index_name, values=[\"value\"], columns=\"spalen\", aggfunc=np.mean)\n",
    "   # # temp = df.pivot(index='new_index_spalen', values=[\"price\"], columns=\"month_cnt\")\n",
    "   # temp.columns = [\"value_spalen_{}\".format(i)  if j[1] != \"\" else j[0] for i, j in enumerate(temp.columns)]\n",
    "   # df = df.merge(temp, on=index_name,  how='left')\n",
    "   # df.drop(index_name, inplace=True, axis=1)\n",
    "    # df = df.merge(temp, left_index=True, right_index=True,  how='left')\n",
    "    \n",
    "    \n",
    "    for col in df.columns.tolist():\n",
    "        if len(df[col].unique()) == 1:\n",
    "            df.drop([col], axis=1, inplace=True)\n",
    "    \n",
    "    df.drop(['new_index_spalen'], axis=1, inplace=True)\n",
    "    \n",
    "    train_df = df[df['value'].notnull()]\n",
    "    test_df = df[df['value'].isnull()]\n",
    "    \n",
    "    for col in list(set(test_df.columns.tolist()) - set(list(['value']))):\n",
    "        if len(test_df[col].unique()) == 1:\n",
    "            test_df.drop([col], axis=1, inplace=True)\n",
    "            train_df.drop([col], axis=1, inplace=True)\n",
    "    \n",
    "    train_df['value'] = np.clip(train_df['value'], 0, 5000)\n",
    "    \n",
    "    df = pd.concat([train_df, test_df])\n",
    "    df, new_cols = one_hot_encoder(df, False, max_num_of_unique_items=30)\n",
    "    \n",
    "    test_df = df[df.month_cnt >= 35]\n",
    "    train_df = df[df.month_cnt <= 34]\n",
    "    \n",
    "    \n",
    "    return test_df, train_df, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flats(df):\n",
    "    flats = reduce_mem_usage(pd.read_csv('./input/flat.csv',\n",
    "                                         encoding='cp1251',\n",
    "                                         parse_dates=['date_salestart','date_settle','sale']))\n",
    "\n",
    "    # flats[\"date_salestart_weekday\"] = flats['date_salestart'].dt.weekday\n",
    "    flats[\"date_salestart_week\"] = flats['date_salestart'].dt.week\n",
    "    # flats[\"date_salestart_day\"] = flats['date_salestart'].dt.day\n",
    "    flats[\"date_salestart_month\"] = flats['date_salestart'].dt.month\n",
    "\n",
    "    # flats[\"date_settle_weekday\"] = flats['date_settle'].dt.weekday\n",
    "    flats[\"date_settle_week\"] = flats['date_settle'].dt.week\n",
    "    # flats[\"date_settle_day\"] = flats['date_settle'].dt.day\n",
    "    flats[\"date_settle_month\"] = flats['date_settle'].dt.month\n",
    "    \n",
    "    \n",
    "    \n",
    "    flats['new_index_spalen'] = flats['id_bulk'] + '-' + flats['spalen'].astype(int).astype(str)\n",
    "    \n",
    "#     flats_cols = list((set(list(flats.columns)) - set(list(df.columns) + \\\n",
    "#                                                       list(['id_bulk'])))) + list(['new_index_spalen'])\n",
    "#     flats = flats[flats_cols]\n",
    "\n",
    "    \n",
    "    \n",
    "#     prices = get_prices()\n",
    "#     prices_cols = list(prices.columns)\n",
    "#     print(\"Flats df shape:\", prices.shape)\n",
    "#     flats = flats.join(prices, how='left', on='id_flatwork')\n",
    "   \n",
    "    aggregations = {\n",
    "            'stage_number': ['max', 'mean'],\n",
    "            'spalen': ['count','sum'],\n",
    "            'square': ['sum', 'mean', 'var', 'max'],\n",
    "            'date_salestart_week': ['max', 'mean'],\n",
    "            'date_salestart_month': ['max', 'mean'],\n",
    "            'date_settle_week': ['max', 'mean'],\n",
    "            'date_settle_month': ['max', 'mean'],\n",
    "            'balcon':['mean', 'count'],\n",
    "#             'section':['mean', 'count'],\n",
    "        }\n",
    "\n",
    "    flats_agg = flats.groupby(['new_index_spalen']).agg(aggregations)\n",
    "    flats_agg.columns = pd.Index(['FLATS_sp_' + e[0] + \"_\" + e[1].upper() for e in flats_agg.columns.tolist()])\n",
    "    \n",
    "#     flats = flats.join(flats_agg, how='left', on='new_index_spalen', rsuffix='_'+groupby_col)\n",
    "    \n",
    "    \n",
    "#     aggregations = {}\n",
    "    \n",
    "#     aggregations = {\n",
    "#             'stage_number': ['max', 'mean'],\n",
    "#             'spalen': ['count','sum'],\n",
    "#             'square': ['sum', 'mean']\n",
    "#         }\n",
    "   \n",
    "#     flats_agg = flats.groupby(['id_bulk']).agg(aggregations)\n",
    "#     flats_agg.columns = pd.Index(['FLATS_' + e[0] + \"_\" + e[1].upper() for e in flats_agg.columns.tolist()])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # flats_agg['INSTAL_COUNT'] = flats.groupby('id_bulk').size()\n",
    "#     del flats, prices\n",
    "\n",
    "#     flats, new_cols = one_hot_encoder(flats, keep_columns=['id_flatwork',\n",
    "#                                                            'id_sec',\n",
    "#                                                            'id_gk',\n",
    "#                                                            'id_bulk',\n",
    "#                                                            'new_index_spalen'])\n",
    "\n",
    "    discard_columns = [\"id_bulk\",\n",
    "    \"section\",\n",
    "    \"date_settle\",\n",
    "    \"date_salestart\",\n",
    "    \"id_gk\",\n",
    "    \"id_flatwork\",\n",
    "    \"Класс объекта\",\n",
    "    \"Количество помещений\",\n",
    "    \"Огорожена территория\",\n",
    "    \"Площадь земельного участка\",\n",
    "    \"Входные группы\",\n",
    "    \"Детский сад\",\n",
    "    \"Школа\",\n",
    "    \"Поликлиника\",\n",
    "    \"ФОК\",\n",
    "    \"Спортивная площадка\",\n",
    "    \"Автомойка\",\n",
    "    \"Кладовые\",\n",
    "    \"Колясочные\",\n",
    "    \"Кондиционирование\",\n",
    "    \"Вентлияция\",\n",
    "    \"Лифт\",\n",
    "    \"Система мусоротведения\",\n",
    "    \"Видеонаблюдение\",\n",
    "    \"Подземная парковка\",\n",
    "    \"Двор без машин\",\n",
    "    \"Машиномест\",\n",
    "    \"Площадь пром. зоны в радиусе 500 м\",\n",
    "    \"Площадь зеленой зоны в радиусе 500 м\",\n",
    "    \"До Кремля\",\n",
    "    \"До ТТК(км)\",\n",
    "    \"До Садового(км)\",\n",
    "    \"До большой дороги на машине(км)\",\n",
    "    \"До удобной авторазвязки на машине(км)\",\n",
    "    \"До метро пешком(км)\",\n",
    "    \"До промки(км)\",\n",
    "    \"До парка(км)\",\n",
    "    \"До парка пешком(км)\",\n",
    "    \"Станций метро от кольца\",\n",
    "    \"Площадь двора\",\n",
    "    \"vid\",\n",
    "    \"sale\",\n",
    "    \"plan_size\",\n",
    "    ]\n",
    "    feats = [f for f in flats_agg.columns.tolist() if f not in discard_columns]\n",
    "\n",
    "    gc.collect()\n",
    "    return flats_agg[feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 6)\n",
      "\n",
      "Starting LightGBM. Train shape: (1202, 101), test shape: (278, 102)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2093]\ttraining's rmse: 33.9742\tvalid_1's rmse: 102.106\n",
      "Current error  117.33855559006179\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[495]\ttraining's rmse: 67.3411\tvalid_1's rmse: 115.933\n",
      "Current error  110.48889846257296\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7023]\ttraining's rmse: 7.19236\tvalid_1's rmse: 90.1697\n",
      "Current error  115.0450428829112\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1004]\ttraining's rmse: 52.6659\tvalid_1's rmse: 85.2674\n",
      "Current error  114.1842641846733\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1504]\ttraining's rmse: 43.6993\tvalid_1's rmse: 94.6552\n",
      "Current error  120.10282247940152\n",
      "97.62638753112711\n",
      "113.03349364692276\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = pd.DataFrame()\n",
    "for spalen in [0]:\n",
    "    test_df, train_df, test_target = get_df(spalen)\n",
    "    # train_df.to_csv('test2.csv', encoding='cp1251', sep=';', decimal=',')\n",
    "    avg_score, pred = test(test_df, train_df, test_target)\n",
    "    avg_score\n",
    "    # mean_squared_error(test_target/test_df['price'], pred/test_df['price'])**0.5\n",
    "    test_df['pred'] = (pred)\n",
    "    test_df['value'] = (test_target)\n",
    "    prediction = pd.concat([prediction, test_df[['id','pred', 'value']]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#test_df, train_df = get_df()\n",
    "\n",
    "# def rmsle(y_true, y_pred):\n",
    "#         assert len(y_true) == len(y_pred)\n",
    "#         return np.sqrt(np.mean(np.power(np.log1p(y_true + 1) - np.log1p(y_pred + 1), 2)))\n",
    "\n",
    "def test(test_df, train_df, test_target):\n",
    "\n",
    "    target_column = 'value'\n",
    "    num_folds = 10\n",
    "    nseeds = 1\n",
    "    target = train_df.pop(target_column)\n",
    "    feats = train_df.columns.tolist()\n",
    "    print(\"\\nStarting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    gc.collect()\n",
    "    # Cross validation model\n",
    "    folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    avg_score = 0\n",
    "    run_times = 0\n",
    "\n",
    "    discard_columns = ['bulk_id', 'bulk_id_1', 'bulk_id_2', 'bulk_id_3', 'bulk_id_4','new_index_unique',\n",
    "                       'new_index_unique_lag_1','new_index_unique_lag_2','new_index_unique_lag_3',\n",
    "                       'new_index_unique_lag_4','new_index_unique_lag_5','new_index_unique_lag_6',\n",
    "                       'new_index_spalen','Курс', 'end_square', 'bulk_id_5', target_column, 'date1']\n",
    "\n",
    "    feats = list(set(list(feats)) - set(discard_columns))\n",
    "#     feats = list(set(list(feats)) - set(not_important_features))\n",
    "\n",
    "    # feats = list(train_df.columns)\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], target)):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], target.iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], target.iloc[valid_idx]\n",
    "        nseeds = nseeds\n",
    "        for s in range(nseeds):\n",
    "            test_df_clear = test_df.copy()\n",
    "            run_times += 1\n",
    "            # LightGBM parameters found by Bayesian optimization\n",
    "            clf = LGBMRegressor(\n",
    "    #                     boosting = 'dart',\n",
    "#                         device_type='gpu',\n",
    "                        boosting='gbdt',\n",
    "                        nthread=4,\n",
    "                        n_estimators=15000,\n",
    "                        learning_rate=0.01,\n",
    "                        num_leaves=34,\n",
    "                        colsample_bytree=0.8,\n",
    "                        subsample=0.87,\n",
    "                        max_depth=-1,\n",
    "                        reg_alpha=0.041545473,\n",
    "                        reg_lambda=0.0735294,\n",
    "                        min_split_gain=0.01,\n",
    "                        min_child_weight=20,\n",
    "                        silent=-1,\n",
    "                        verbose=-1, \n",
    "                        seed=s,\n",
    "                        random_state=s,\n",
    "                        )\n",
    "            clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "                             eval_metric='rmse', verbose= 15000, early_stopping_rounds= 300)\n",
    "\n",
    "            oof_preds[valid_idx] = clf.predict(valid_x, num_iteration=clf.best_iteration_)\n",
    "            y_pred = clf.predict(test_df_clear[feats], num_iteration=clf.best_iteration_)\n",
    "    #         test_df_clear[target_column] = y_pred\n",
    "\n",
    "    #         temp, new_cols = add_lags(test_df_clear, feat='value', index='new_index_spalen', by_col='month_cnt')\n",
    "    #         test_df_clear.drop(new_cols, inplace=True, axis=1)\n",
    "    #         test_df_clear = test_df_clear.merge(temp[new_cols], on='new_index_spalen',  how='left')\n",
    "    #         y_pred = clf.predict(test_df_clear[feats], num_iteration=clf.best_iteration_)\n",
    "\n",
    "            sub_preds +=  pd.Series(y_pred).values #/ folds.n_splits\n",
    "\n",
    "            oof_score = mean_squared_error(valid_y, oof_preds[valid_idx])**0.5\n",
    "            test_score = mean_squared_error(test_target, y_pred)**0.5\n",
    "#             oof_score = roc_auc_score(valid_y, oof_preds[valid_idx])\n",
    "#             test_score = roc_auc_score(test_target, y_pred)\n",
    "            fold_importance_df = pd.DataFrame()\n",
    "            fold_importance_df[\"feature\"] = feats\n",
    "            fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "            fold_importance_df[\"fold\"] = n_fold + 1\n",
    "            fold_importance_df[\"seed\"] = s\n",
    "            fold_importance_df['oof_score'] = oof_score\n",
    "            fold_importance_df['test_score'] = test_score\n",
    "            feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "            # print('Fold %2d Seed %i AUC : %.6f' % (n_fold + 1, s, score))\n",
    "            avg_score +=  oof_score\n",
    "            print('Current error ', test_score)\n",
    "    #del clf, train_x, train_y, valid_x, valid_y\n",
    "    gc.collect()\n",
    "\n",
    "    print(avg_score/run_times)\n",
    "    print(mean_squared_error(test_target, sub_preds/run_times)**0.5)\n",
    "#     print(roc_auc_score(test_target, y_pred))\n",
    "    print('\\n')\n",
    "#     return roc_auc_score(test_target, y_pred), sub_preds/run_times\n",
    "    return mean_squared_error(test_target, sub_preds/run_times)**0.5, avg_score/run_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 78), test shape: (1736, 79)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4223]\ttraining's rmse: 81.1632\tvalid_1's rmse: 232.837\n",
      "Current error  239.30072209590162\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4877]\ttraining's rmse: 73.0848\tvalid_1's rmse: 216.564\n",
      "Current error  240.0993724345016\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2785]\ttraining's rmse: 103.552\tvalid_1's rmse: 199.05\n",
      "Current error  237.97526233702183\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[9467]\ttraining's rmse: 45.4885\tvalid_1's rmse: 215.49\n",
      "Current error  238.79917854387136\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2899]\ttraining's rmse: 102.147\tvalid_1's rmse: 180.39\n",
      "Current error  239.07495718963597\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1388]\ttraining's rmse: 134.142\tvalid_1's rmse: 200.014\n",
      "Current error  238.90358064498182\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4611]\ttraining's rmse: 76.3136\tvalid_1's rmse: 230.753\n",
      "Current error  236.10906277568319\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3888]\ttraining's rmse: 86.3837\tvalid_1's rmse: 196.066\n",
      "Current error  236.03165350490494\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6795]\ttraining's rmse: 59.1436\tvalid_1's rmse: 209.412\n",
      "Current error  235.06866405880857\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3758]\ttraining's rmse: 86.2573\tvalid_1's rmse: 252.415\n",
      "Current error  240.21051124223854\n",
      "213.29888581462848\n",
      "233.7813107066042\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4544]\ttraining's rmse: 76.3359\tvalid_1's rmse: 236.154\n",
      "Current error  240.4088973656645\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2544]\ttraining's rmse: 102.73\tvalid_1's rmse: 216.733\n",
      "Current error  239.54620424250515\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2773]\ttraining's rmse: 102.258\tvalid_1's rmse: 200.68\n",
      "Current error  236.67757668843709\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[9960]\ttraining's rmse: 41.6508\tvalid_1's rmse: 213.51\n",
      "Current error  240.08691840414195\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3621]\ttraining's rmse: 89.2915\tvalid_1's rmse: 181.579\n",
      "Current error  239.74648368982685\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1150]\ttraining's rmse: 141.714\tvalid_1's rmse: 201.193\n",
      "Current error  236.1052398352193\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2556]\ttraining's rmse: 103.739\tvalid_1's rmse: 234.873\n",
      "Current error  236.91141518995596\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3609]\ttraining's rmse: 88.3884\tvalid_1's rmse: 196.26\n",
      "Current error  236.37615593013035\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6643]\ttraining's rmse: 58.6682\tvalid_1's rmse: 208.827\n",
      "Current error  235.71269062562624\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4164]\ttraining's rmse: 80.3225\tvalid_1's rmse: 253.184\n",
      "Current error  242.00474272078068\n",
      "214.29932186985258\n",
      "233.98479062528767\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5808]\ttraining's rmse: 65.556\tvalid_1's rmse: 231.059\n",
      "Current error  239.2346974264457\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4852]\ttraining's rmse: 73.5235\tvalid_1's rmse: 215.767\n",
      "Current error  239.20177310204699\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2341]\ttraining's rmse: 110.401\tvalid_1's rmse: 201.105\n",
      "Current error  237.17594951036443\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7750]\ttraining's rmse: 53.0224\tvalid_1's rmse: 215.677\n",
      "Current error  240.15893169668578\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4057]\ttraining's rmse: 83.8347\tvalid_1's rmse: 180.576\n",
      "Current error  240.32941839515456\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1032]\ttraining's rmse: 146.577\tvalid_1's rmse: 198.39\n",
      "Current error  238.85034688252745\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3841]\ttraining's rmse: 83.4865\tvalid_1's rmse: 230.941\n",
      "Current error  234.6539331634268\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2650]\ttraining's rmse: 103.113\tvalid_1's rmse: 195.988\n",
      "Current error  236.05951564608506\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5887]\ttraining's rmse: 65.5881\tvalid_1's rmse: 209.891\n",
      "Current error  234.18198683041717\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5701]\ttraining's rmse: 65.2303\tvalid_1's rmse: 252.002\n",
      "Current error  240.83598200649504\n",
      "213.13967535962553\n",
      "233.5725604514105\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3513]\ttraining's rmse: 89.9292\tvalid_1's rmse: 234.76\n",
      "Current error  238.1371750828701\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3703]\ttraining's rmse: 85.6598\tvalid_1's rmse: 217.672\n",
      "Current error  238.60298385912907\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2914]\ttraining's rmse: 98.6542\tvalid_1's rmse: 195.205\n",
      "Current error  237.8046088703803\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6312]\ttraining's rmse: 62.5223\tvalid_1's rmse: 218.388\n",
      "Current error  238.19159860080381\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4104]\ttraining's rmse: 83.0061\tvalid_1's rmse: 178.374\n",
      "Current error  238.55984227926953\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1367]\ttraining's rmse: 133.339\tvalid_1's rmse: 198.101\n",
      "Current error  237.07276297023623\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5856]\ttraining's rmse: 63.0057\tvalid_1's rmse: 231.299\n",
      "Current error  236.76917131321048\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3705]\ttraining's rmse: 87.2162\tvalid_1's rmse: 197.21\n",
      "Current error  236.2717107467215\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6221]\ttraining's rmse: 62.1403\tvalid_1's rmse: 207.473\n",
      "Current error  236.2474601149382\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5708]\ttraining's rmse: 65.5303\tvalid_1's rmse: 248.696\n",
      "Current error  241.86428114466162\n",
      "212.71787300074\n",
      "233.661561253505\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3953]\ttraining's rmse: 81.9027\tvalid_1's rmse: 234.571\n",
      "Current error  238.23144546532976\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4258]\ttraining's rmse: 77.2122\tvalid_1's rmse: 217.251\n",
      "Current error  239.81180507519474\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2660]\ttraining's rmse: 103.333\tvalid_1's rmse: 201.234\n",
      "Current error  237.721602820895\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8323]\ttraining's rmse: 47.8429\tvalid_1's rmse: 219.198\n",
      "Current error  238.86201690716226\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3202]\ttraining's rmse: 92.4701\tvalid_1's rmse: 182.806\n",
      "Current error  237.08910336913377\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[910]\ttraining's rmse: 151.949\tvalid_1's rmse: 200.94\n",
      "Current error  238.64367885579898\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5189]\ttraining's rmse: 68.1254\tvalid_1's rmse: 232.906\n",
      "Current error  236.49458688692812\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5102]\ttraining's rmse: 69.9998\tvalid_1's rmse: 197.347\n",
      "Current error  238.0193881995652\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5788]\ttraining's rmse: 62.9667\tvalid_1's rmse: 214.23\n",
      "Current error  234.50447777824533\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4378]\ttraining's rmse: 76.4345\tvalid_1's rmse: 250.027\n",
      "Current error  240.99393459719556\n",
      "215.05104708087646\n",
      "233.45886608943496\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3107]\ttraining's rmse: 94.8423\tvalid_1's rmse: 236.635\n",
      "Current error  237.38835285434175\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3378]\ttraining's rmse: 89.353\tvalid_1's rmse: 214.205\n",
      "Current error  237.89324226116477\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2360]\ttraining's rmse: 109.936\tvalid_1's rmse: 198.463\n",
      "Current error  235.97215191533567\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[10183]\ttraining's rmse: 40.4844\tvalid_1's rmse: 219.159\n",
      "Current error  239.24380668714747\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2877]\ttraining's rmse: 99.123\tvalid_1's rmse: 179.62\n",
      "Current error  240.31810634993516\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1414]\ttraining's rmse: 132.232\tvalid_1's rmse: 199.657\n",
      "Current error  239.38527355342023\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4566]\ttraining's rmse: 74.5759\tvalid_1's rmse: 231.519\n",
      "Current error  236.03517742683306\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5249]\ttraining's rmse: 68.9\tvalid_1's rmse: 195.718\n",
      "Current error  239.94851880588544\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6702]\ttraining's rmse: 58.8242\tvalid_1's rmse: 210.885\n",
      "Current error  235.8410605689332\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3413]\ttraining's rmse: 89.5833\tvalid_1's rmse: 254.253\n",
      "Current error  239.093700019387\n",
      "214.01140316633504\n",
      "233.85699132240075\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4230]\ttraining's rmse: 78.4597\tvalid_1's rmse: 235.566\n",
      "Current error  236.54376711733528\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3725]\ttraining's rmse: 84.5706\tvalid_1's rmse: 217.257\n",
      "Current error  239.0761814230236\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3546]\ttraining's rmse: 88.5834\tvalid_1's rmse: 197.413\n",
      "Current error  237.45359147234655\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[9882]\ttraining's rmse: 41.0837\tvalid_1's rmse: 218.383\n",
      "Current error  239.21483023320837\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2466]\ttraining's rmse: 106.742\tvalid_1's rmse: 181.602\n",
      "Current error  237.4250057422302\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1050]\ttraining's rmse: 145.855\tvalid_1's rmse: 199.495\n",
      "Current error  235.07322694364407\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5577]\ttraining's rmse: 63.8735\tvalid_1's rmse: 231.47\n",
      "Current error  233.7461165681821\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4593]\ttraining's rmse: 74.9413\tvalid_1's rmse: 194.736\n",
      "Current error  237.83562654378397\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5816]\ttraining's rmse: 63.8017\tvalid_1's rmse: 209.076\n",
      "Current error  233.47178545544904\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4272]\ttraining's rmse: 79.1575\tvalid_1's rmse: 253.252\n",
      "Current error  242.50450434814726\n",
      "213.82502953676985\n",
      "232.7662029211418\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3256]\ttraining's rmse: 93.3339\tvalid_1's rmse: 234.876\n",
      "Current error  237.85667332176772\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3334]\ttraining's rmse: 91.842\tvalid_1's rmse: 217.564\n",
      "Current error  239.98805485221948\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2639]\ttraining's rmse: 105.442\tvalid_1's rmse: 197.018\n",
      "Current error  236.34306802911948\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8393]\ttraining's rmse: 50.3438\tvalid_1's rmse: 213.588\n",
      "Current error  240.24949942142499\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3510]\ttraining's rmse: 92.0676\tvalid_1's rmse: 180.405\n",
      "Current error  239.77195959446937\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1355]\ttraining's rmse: 134.353\tvalid_1's rmse: 199.991\n",
      "Current error  240.07669666223282\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2840]\ttraining's rmse: 99.143\tvalid_1's rmse: 232.273\n",
      "Current error  234.1589871710407\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3885]\ttraining's rmse: 85.0518\tvalid_1's rmse: 195.418\n",
      "Current error  236.9491323100349\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5121]\ttraining's rmse: 72.8355\tvalid_1's rmse: 209.414\n",
      "Current error  235.35632426953663\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2737]\ttraining's rmse: 100.73\tvalid_1's rmse: 253.073\n",
      "Current error  240.7871269820347\n",
      "213.36196353502402\n",
      "234.0554175514876\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4669]\ttraining's rmse: 74.8065\tvalid_1's rmse: 233.894\n",
      "Current error  239.31260394675166\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3396]\ttraining's rmse: 90.1063\tvalid_1's rmse: 213.434\n",
      "Current error  239.3353830944293\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2733]\ttraining's rmse: 102.161\tvalid_1's rmse: 198.709\n",
      "Current error  237.40806336956948\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8088]\ttraining's rmse: 51.5337\tvalid_1's rmse: 215.085\n",
      "Current error  239.16219192042087\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3357]\ttraining's rmse: 92.6682\tvalid_1's rmse: 180.51\n",
      "Current error  240.53951104713525\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1391]\ttraining's rmse: 133.251\tvalid_1's rmse: 201.66\n",
      "Current error  238.65253151965155\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2724]\ttraining's rmse: 99.6693\tvalid_1's rmse: 232.848\n",
      "Current error  234.96653794280684\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3577]\ttraining's rmse: 89.6106\tvalid_1's rmse: 194.432\n",
      "Current error  236.32963345098273\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5201]\ttraining's rmse: 70.7409\tvalid_1's rmse: 208.003\n",
      "Current error  235.34524232813348\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8929]\ttraining's rmse: 46.5243\tvalid_1's rmse: 246.584\n",
      "Current error  242.57653414080434\n",
      "212.51580562464238\n",
      "234.12229412357175\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4749]\ttraining's rmse: 73.2395\tvalid_1's rmse: 231.206\n",
      "Current error  243.2246828713841\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3778]\ttraining's rmse: 83.925\tvalid_1's rmse: 215.983\n",
      "Current error  241.45082191789265\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3877]\ttraining's rmse: 85.0275\tvalid_1's rmse: 198.646\n",
      "Current error  238.7915597804047\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[12355]\ttraining's rmse: 32.67\tvalid_1's rmse: 216.469\n",
      "Current error  242.95939369288556\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4199]\ttraining's rmse: 80.9766\tvalid_1's rmse: 180.346\n",
      "Current error  239.18915626554895\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1056]\ttraining's rmse: 145.282\tvalid_1's rmse: 198.463\n",
      "Current error  239.5144425645824\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4244]\ttraining's rmse: 77.4645\tvalid_1's rmse: 229.916\n",
      "Current error  236.6510944922653\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4220]\ttraining's rmse: 79.6445\tvalid_1's rmse: 198.146\n",
      "Current error  239.9495516196605\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4022]\ttraining's rmse: 82.0042\tvalid_1's rmse: 210.668\n",
      "Current error  233.6121587522093\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2652]\ttraining's rmse: 102.055\tvalid_1's rmse: 253.26\n",
      "Current error  240.41087701799782\n",
      "213.3103931263663\n",
      "235.09254461179194\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3984]\ttraining's rmse: 82.9175\tvalid_1's rmse: 234.04\n",
      "Current error  240.63638972056623\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3951]\ttraining's rmse: 83.1828\tvalid_1's rmse: 218.554\n",
      "Current error  240.83869254407787\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3138]\ttraining's rmse: 95.9808\tvalid_1's rmse: 199.054\n",
      "Current error  236.45495775601765\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[9656]\ttraining's rmse: 43.7669\tvalid_1's rmse: 218.122\n",
      "Current error  239.53129742380878\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3162]\ttraining's rmse: 96.1874\tvalid_1's rmse: 179.121\n",
      "Current error  239.20070826237657\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1192]\ttraining's rmse: 140.34\tvalid_1's rmse: 199.874\n",
      "Current error  239.08675098275916\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3128]\ttraining's rmse: 93.751\tvalid_1's rmse: 234.201\n",
      "Current error  235.45686549025123\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2750]\ttraining's rmse: 102.417\tvalid_1's rmse: 197.061\n",
      "Current error  236.52414196623178\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4266]\ttraining's rmse: 81.5159\tvalid_1's rmse: 211.456\n",
      "Current error  233.81393153763997\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6505]\ttraining's rmse: 59.5228\tvalid_1's rmse: 249.096\n",
      "Current error  243.51644273515728\n",
      "214.05793825124778\n",
      "234.2738207135634\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4452]\ttraining's rmse: 77.0739\tvalid_1's rmse: 233.762\n",
      "Current error  239.97135029613045\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2617]\ttraining's rmse: 102.413\tvalid_1's rmse: 215.155\n",
      "Current error  240.93816680419843\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2766]\ttraining's rmse: 101.775\tvalid_1's rmse: 198.088\n",
      "Current error  236.7483953658453\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[10457]\ttraining's rmse: 40.0234\tvalid_1's rmse: 213.847\n",
      "Current error  243.92662004098972\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3638]\ttraining's rmse: 89.4565\tvalid_1's rmse: 182.446\n",
      "Current error  239.81369812085336\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1292]\ttraining's rmse: 135.005\tvalid_1's rmse: 200.071\n",
      "Current error  240.0202520737543\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4051]\ttraining's rmse: 80.3937\tvalid_1's rmse: 230.385\n",
      "Current error  236.96996254635943\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4746]\ttraining's rmse: 75.2661\tvalid_1's rmse: 192.05\n",
      "Current error  239.293747400104\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7004]\ttraining's rmse: 56.5611\tvalid_1's rmse: 208.218\n",
      "Current error  235.8749888712725\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7194]\ttraining's rmse: 55.3626\tvalid_1's rmse: 249.147\n",
      "Current error  241.91753575051666\n",
      "212.31686995055802\n",
      "234.93940347497198\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3399]\ttraining's rmse: 88.9674\tvalid_1's rmse: 236.377\n",
      "Current error  238.06319470130038\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3118]\ttraining's rmse: 92.3713\tvalid_1's rmse: 220.395\n",
      "Current error  237.62570337917677\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2964]\ttraining's rmse: 96.0974\tvalid_1's rmse: 200.357\n",
      "Current error  236.61380736613796\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[10935]\ttraining's rmse: 35.1945\tvalid_1's rmse: 220.415\n",
      "Current error  238.86773320022868\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3169]\ttraining's rmse: 93.9419\tvalid_1's rmse: 183.353\n",
      "Current error  238.52178278094135\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1471]\ttraining's rmse: 130.12\tvalid_1's rmse: 202.227\n",
      "Current error  236.5267401574248\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4629]\ttraining's rmse: 72.4081\tvalid_1's rmse: 232.529\n",
      "Current error  236.08782086570162\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2482]\ttraining's rmse: 104.656\tvalid_1's rmse: 199.453\n",
      "Current error  234.485680341127\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5795]\ttraining's rmse: 61.9575\tvalid_1's rmse: 214.893\n",
      "Current error  233.7158795704959\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4195]\ttraining's rmse: 78.2143\tvalid_1's rmse: 254.896\n",
      "Current error  241.1913074462791\n",
      "216.4895119878381\n",
      "232.94554859745108\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5418]\ttraining's rmse: 67.3287\tvalid_1's rmse: 232.827\n",
      "Current error  239.1752530216229\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4441]\ttraining's rmse: 76.3579\tvalid_1's rmse: 216.191\n",
      "Current error  236.89042619654606\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3108]\ttraining's rmse: 95.8285\tvalid_1's rmse: 198.155\n",
      "Current error  239.4304654904692\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8704]\ttraining's rmse: 46.0832\tvalid_1's rmse: 214.873\n",
      "Current error  241.38467218698932\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4812]\ttraining's rmse: 74.642\tvalid_1's rmse: 180.322\n",
      "Current error  241.90953012523474\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1044]\ttraining's rmse: 144.841\tvalid_1's rmse: 202.749\n",
      "Current error  237.81752844251207\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5298]\ttraining's rmse: 66.9054\tvalid_1's rmse: 229.914\n",
      "Current error  236.0132796402534\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3982]\ttraining's rmse: 84.1297\tvalid_1's rmse: 193.669\n",
      "Current error  237.67147001121447\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4756]\ttraining's rmse: 74.0366\tvalid_1's rmse: 208.027\n",
      "Current error  236.76487840346346\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4134]\ttraining's rmse: 80.0751\tvalid_1's rmse: 249.621\n",
      "Current error  243.4305504618302\n",
      "212.6348490775831\n",
      "234.55869509366696\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4728]\ttraining's rmse: 75.0056\tvalid_1's rmse: 234.97\n",
      "Current error  240.46194636199976\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3897]\ttraining's rmse: 83.1354\tvalid_1's rmse: 216.947\n",
      "Current error  239.50480011742073\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3100]\ttraining's rmse: 96.4619\tvalid_1's rmse: 197.118\n",
      "Current error  238.83489868449695\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[9195]\ttraining's rmse: 44.6056\tvalid_1's rmse: 217.4\n",
      "Current error  240.25955015387737\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3585]\ttraining's rmse: 88.8752\tvalid_1's rmse: 181.019\n",
      "Current error  241.0252939869984\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1290]\ttraining's rmse: 136.615\tvalid_1's rmse: 201.222\n",
      "Current error  240.01817668269297\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5365]\ttraining's rmse: 66.703\tvalid_1's rmse: 230.172\n",
      "Current error  237.68529503029853\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2697]\ttraining's rmse: 102.292\tvalid_1's rmse: 196.628\n",
      "Current error  239.19877637628903\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6575]\ttraining's rmse: 58.6505\tvalid_1's rmse: 208.585\n",
      "Current error  235.52608973417014\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6579]\ttraining's rmse: 57.8539\tvalid_1's rmse: 249.041\n",
      "Current error  243.37829539556975\n",
      "213.3102606062771\n",
      "235.14871827018254\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4179]\ttraining's rmse: 80.4305\tvalid_1's rmse: 235.201\n",
      "Current error  238.99395686702024\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3425]\ttraining's rmse: 90.3119\tvalid_1's rmse: 217.559\n",
      "Current error  240.9377501136569\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3151]\ttraining's rmse: 97.2758\tvalid_1's rmse: 199.247\n",
      "Current error  237.78532728218485\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[11454]\ttraining's rmse: 36.5686\tvalid_1's rmse: 214.22\n",
      "Current error  241.4887299520483\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4041]\ttraining's rmse: 84.7073\tvalid_1's rmse: 180.936\n",
      "Current error  241.1571344254019\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1249]\ttraining's rmse: 138.081\tvalid_1's rmse: 199.154\n",
      "Current error  239.70167129908975\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4168]\ttraining's rmse: 79.6092\tvalid_1's rmse: 230.844\n",
      "Current error  236.0926780687227\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4245]\ttraining's rmse: 80.9685\tvalid_1's rmse: 195.808\n",
      "Current error  239.38877908674166\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6973]\ttraining's rmse: 58.2462\tvalid_1's rmse: 208.525\n",
      "Current error  235.9226724445057\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6622]\ttraining's rmse: 59.35\tvalid_1's rmse: 251.497\n",
      "Current error  243.4569695581079\n",
      "213.29904089302636\n",
      "234.96113251454702\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3868]\ttraining's rmse: 84.7549\tvalid_1's rmse: 235.377\n",
      "Current error  240.70575029476478\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4977]\ttraining's rmse: 72.6647\tvalid_1's rmse: 216.974\n",
      "Current error  241.14074364860753\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2688]\ttraining's rmse: 103.922\tvalid_1's rmse: 198.489\n",
      "Current error  238.1599987840215\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8192]\ttraining's rmse: 50.668\tvalid_1's rmse: 218.209\n",
      "Current error  238.7966108094764\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4090]\ttraining's rmse: 83.1448\tvalid_1's rmse: 178.474\n",
      "Current error  239.58582748031523\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1260]\ttraining's rmse: 137.65\tvalid_1's rmse: 200.816\n",
      "Current error  240.98693670526652\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3502]\ttraining's rmse: 88.5138\tvalid_1's rmse: 231.862\n",
      "Current error  234.7389406175388\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4369]\ttraining's rmse: 79.1209\tvalid_1's rmse: 196.251\n",
      "Current error  237.7776883314779\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4962]\ttraining's rmse: 73.9886\tvalid_1's rmse: 209.142\n",
      "Current error  236.19372280163586\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5901]\ttraining's rmse: 64.4439\tvalid_1's rmse: 248.343\n",
      "Current error  243.39101592505128\n",
      "213.3936892110683\n",
      "234.86227560374212\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4612]\ttraining's rmse: 73.1178\tvalid_1's rmse: 234.755\n",
      "Current error  239.50732314700832\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3489]\ttraining's rmse: 85.481\tvalid_1's rmse: 217.178\n",
      "Current error  238.34142411274902\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2512]\ttraining's rmse: 106.328\tvalid_1's rmse: 198.564\n",
      "Current error  239.30442487525806\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[11229]\ttraining's rmse: 34.8517\tvalid_1's rmse: 219.337\n",
      "Current error  236.75354250743908\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4120]\ttraining's rmse: 79.7876\tvalid_1's rmse: 181.014\n",
      "Current error  239.06389573401916\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1688]\ttraining's rmse: 123.888\tvalid_1's rmse: 199.531\n",
      "Current error  240.48328251681255\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4222]\ttraining's rmse: 76.6106\tvalid_1's rmse: 230.163\n",
      "Current error  235.73173465667588\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3918]\ttraining's rmse: 81.1322\tvalid_1's rmse: 197.546\n",
      "Current error  237.02756101774247\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6884]\ttraining's rmse: 53.9325\tvalid_1's rmse: 209.796\n",
      "Current error  234.01801551135173\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3136]\ttraining's rmse: 91.6397\tvalid_1's rmse: 257.695\n",
      "Current error  238.84544230079965\n",
      "214.55792357870345\n",
      "233.4020522607336\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4507]\ttraining's rmse: 77.0825\tvalid_1's rmse: 231.709\n",
      "Current error  239.8983427161429\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4901]\ttraining's rmse: 72.0076\tvalid_1's rmse: 216.389\n",
      "Current error  239.32412039872776\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2085]\ttraining's rmse: 114.675\tvalid_1's rmse: 200.152\n",
      "Current error  235.0903667341093\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[11144]\ttraining's rmse: 37.2804\tvalid_1's rmse: 214.026\n",
      "Current error  238.43211839919275\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3032]\ttraining's rmse: 94.6642\tvalid_1's rmse: 179.233\n",
      "Current error  238.95213779426325\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1139]\ttraining's rmse: 141.93\tvalid_1's rmse: 198.734\n",
      "Current error  236.75650458318114\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3702]\ttraining's rmse: 84.7705\tvalid_1's rmse: 231.082\n",
      "Current error  233.70903845282757\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3779]\ttraining's rmse: 86.0256\tvalid_1's rmse: 196.143\n",
      "Current error  237.27276663913855\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8060]\ttraining's rmse: 49.9779\tvalid_1's rmse: 209.493\n",
      "Current error  235.84312095961855\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5595]\ttraining's rmse: 65.8903\tvalid_1's rmse: 253.087\n",
      "Current error  241.33812759476083\n",
      "213.00488216115036\n",
      "232.97071069817508\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3294]\ttraining's rmse: 90.428\tvalid_1's rmse: 235.315\n",
      "Current error  238.360424782919\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3365]\ttraining's rmse: 90.2921\tvalid_1's rmse: 216.974\n",
      "Current error  239.31957679095564\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5247]\ttraining's rmse: 68.807\tvalid_1's rmse: 198.864\n",
      "Current error  238.23930341457387\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7012]\ttraining's rmse: 56.7107\tvalid_1's rmse: 219.685\n",
      "Current error  236.93149698010504\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3445]\ttraining's rmse: 90.4845\tvalid_1's rmse: 185.848\n",
      "Current error  239.4507291038899\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1305]\ttraining's rmse: 136.038\tvalid_1's rmse: 200.927\n",
      "Current error  238.40555041803083\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2550]\ttraining's rmse: 102.311\tvalid_1's rmse: 234.108\n",
      "Current error  234.02597030755197\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4622]\ttraining's rmse: 76.4425\tvalid_1's rmse: 197.778\n",
      "Current error  239.3608789708761\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6645]\ttraining's rmse: 57.6412\tvalid_1's rmse: 212.667\n",
      "Current error  232.99657710170197\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5144]\ttraining's rmse: 69.699\tvalid_1's rmse: 251.687\n",
      "Current error  242.51344796461763\n",
      "215.38537803577066\n",
      "233.56144833065267\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4412]\ttraining's rmse: 76.6692\tvalid_1's rmse: 233.259\n",
      "Current error  240.5787655159644\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2616]\ttraining's rmse: 101.381\tvalid_1's rmse: 218.828\n",
      "Current error  239.3976938404234\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3290]\ttraining's rmse: 94.021\tvalid_1's rmse: 198.106\n",
      "Current error  237.77543934946308\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7420]\ttraining's rmse: 52.9216\tvalid_1's rmse: 216.566\n",
      "Current error  240.6056473716942\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3322]\ttraining's rmse: 92.3891\tvalid_1's rmse: 178.702\n",
      "Current error  241.05299869198996\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1231]\ttraining's rmse: 139.135\tvalid_1's rmse: 201.942\n",
      "Current error  239.79995027305492\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3887]\ttraining's rmse: 81.4142\tvalid_1's rmse: 231.746\n",
      "Current error  237.16197182405318\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3274]\ttraining's rmse: 92.3858\tvalid_1's rmse: 197.362\n",
      "Current error  238.0419223232006\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5731]\ttraining's rmse: 64.7361\tvalid_1's rmse: 210.396\n",
      "Current error  232.56318032490879\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7819]\ttraining's rmse: 51.391\tvalid_1's rmse: 252.337\n",
      "Current error  244.12159157241854\n",
      "213.92436385911915\n",
      "234.7334478529853\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4432]\ttraining's rmse: 76.8743\tvalid_1's rmse: 232.153\n",
      "Current error  237.3823405217772\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2793]\ttraining's rmse: 98.4868\tvalid_1's rmse: 216.327\n",
      "Current error  238.59479627182353\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2274]\ttraining's rmse: 110.047\tvalid_1's rmse: 199.652\n",
      "Current error  237.589503457092\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[14083]\ttraining's rmse: 27.9152\tvalid_1's rmse: 216.663\n",
      "Current error  240.27715127419327\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4597]\ttraining's rmse: 76.3215\tvalid_1's rmse: 181.721\n",
      "Current error  239.33673041631266\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1262]\ttraining's rmse: 136.619\tvalid_1's rmse: 200.889\n",
      "Current error  238.16717832628294\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4585]\ttraining's rmse: 73.8322\tvalid_1's rmse: 230.894\n",
      "Current error  235.7622877912534\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2868]\ttraining's rmse: 99.5077\tvalid_1's rmse: 197.057\n",
      "Current error  235.4573152002282\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5392]\ttraining's rmse: 68.4922\tvalid_1's rmse: 209.08\n",
      "Current error  234.1382998204972\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4379]\ttraining's rmse: 76.094\tvalid_1's rmse: 254.151\n",
      "Current error  238.73912541539306\n",
      "213.8588080673695\n",
      "233.136661163109\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6188]\ttraining's rmse: 61.381\tvalid_1's rmse: 230.123\n",
      "Current error  241.68742877808162\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4418]\ttraining's rmse: 77.0435\tvalid_1's rmse: 215.884\n",
      "Current error  239.32279981071443\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3261]\ttraining's rmse: 94.7816\tvalid_1's rmse: 197\n",
      "Current error  238.26463898289944\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[10238]\ttraining's rmse: 41.4889\tvalid_1's rmse: 216.683\n",
      "Current error  240.44727433165983\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3522]\ttraining's rmse: 89.3809\tvalid_1's rmse: 179.57\n",
      "Current error  237.7461472273318\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1035]\ttraining's rmse: 146.54\tvalid_1's rmse: 200.506\n",
      "Current error  238.6343336175489\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3837]\ttraining's rmse: 84.6132\tvalid_1's rmse: 231.479\n",
      "Current error  234.50390878457586\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5260]\ttraining's rmse: 71.0124\tvalid_1's rmse: 194.814\n",
      "Current error  238.26889960339207\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6934]\ttraining's rmse: 57.7041\tvalid_1's rmse: 210.559\n",
      "Current error  236.13042751877896\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7310]\ttraining's rmse: 54.7707\tvalid_1's rmse: 248.779\n",
      "Current error  244.5183825026089\n",
      "212.53963535741656\n",
      "234.12829114111364\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3761]\ttraining's rmse: 84.9885\tvalid_1's rmse: 233.595\n",
      "Current error  239.43605011690607\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3098]\ttraining's rmse: 94.3979\tvalid_1's rmse: 217.274\n",
      "Current error  237.85961063159252\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5071]\ttraining's rmse: 72.4144\tvalid_1's rmse: 198.165\n",
      "Current error  240.07756220471364\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8116]\ttraining's rmse: 51.6127\tvalid_1's rmse: 214.785\n",
      "Current error  240.25570202549832\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4737]\ttraining's rmse: 76.4557\tvalid_1's rmse: 180.983\n",
      "Current error  242.8486288656111\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[948]\ttraining's rmse: 149.428\tvalid_1's rmse: 201.413\n",
      "Current error  238.47457634171272\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4807]\ttraining's rmse: 72.6201\tvalid_1's rmse: 231.049\n",
      "Current error  234.80122321741277\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4428]\ttraining's rmse: 79.7778\tvalid_1's rmse: 196.346\n",
      "Current error  238.58524021231506\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7686]\ttraining's rmse: 52.6367\tvalid_1's rmse: 207.873\n",
      "Current error  235.80382177194747\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5761]\ttraining's rmse: 64.6882\tvalid_1's rmse: 250.546\n",
      "Current error  241.9814410873686\n",
      "213.2029356587518\n",
      "234.3740504075938\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3005]\ttraining's rmse: 96.5219\tvalid_1's rmse: 233.707\n",
      "Current error  237.24788605005145\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3443]\ttraining's rmse: 88.3621\tvalid_1's rmse: 219.616\n",
      "Current error  241.79759475480415\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3373]\ttraining's rmse: 92.4141\tvalid_1's rmse: 199.563\n",
      "Current error  238.24063613062498\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[9272]\ttraining's rmse: 45.1454\tvalid_1's rmse: 215.152\n",
      "Current error  241.32665980515335\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3616]\ttraining's rmse: 90.0036\tvalid_1's rmse: 183.153\n",
      "Current error  240.0911560134634\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[886]\ttraining's rmse: 152.699\tvalid_1's rmse: 201.081\n",
      "Current error  238.74714758667537\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3055]\ttraining's rmse: 95.2713\tvalid_1's rmse: 230.407\n",
      "Current error  234.25887673023024\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3932]\ttraining's rmse: 84.3597\tvalid_1's rmse: 196.805\n",
      "Current error  238.4521193192159\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7064]\ttraining's rmse: 55.5558\tvalid_1's rmse: 210.017\n",
      "Current error  236.27978235383486\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4456]\ttraining's rmse: 76.9784\tvalid_1's rmse: 251.703\n",
      "Current error  238.74100743958516\n",
      "214.12035810399175\n",
      "234.08202337381184\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3722]\ttraining's rmse: 86.0929\tvalid_1's rmse: 235.071\n",
      "Current error  238.36652372388022\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4655]\ttraining's rmse: 73.5814\tvalid_1's rmse: 218.146\n",
      "Current error  239.00394885503596\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3669]\ttraining's rmse: 88.3285\tvalid_1's rmse: 198.182\n",
      "Current error  238.9991782270294\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[11116]\ttraining's rmse: 36.0408\tvalid_1's rmse: 216.89\n",
      "Current error  237.85784497379143\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2785]\ttraining's rmse: 102.418\tvalid_1's rmse: 181.791\n",
      "Current error  238.68345106307046\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1228]\ttraining's rmse: 138.36\tvalid_1's rmse: 200.208\n",
      "Current error  237.25492312137914\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5170]\ttraining's rmse: 67.228\tvalid_1's rmse: 233.331\n",
      "Current error  235.4748386651326\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3543]\ttraining's rmse: 87.9786\tvalid_1's rmse: 197.077\n",
      "Current error  236.74585821373188\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5915]\ttraining's rmse: 63.2956\tvalid_1's rmse: 209.981\n",
      "Current error  234.7015663433493\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4653]\ttraining's rmse: 73.4239\tvalid_1's rmse: 251.543\n",
      "Current error  240.49269143937443\n",
      "214.22194243400517\n",
      "233.224922542857\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 79), test shape: (1736, 80)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5915]\ttraining's rmse: 64.0106\tvalid_1's rmse: 230.578\n",
      "Current error  239.23356169275306\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5123]\ttraining's rmse: 69.8087\tvalid_1's rmse: 216.345\n",
      "Current error  240.27774259717094\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2047]\ttraining's rmse: 115.009\tvalid_1's rmse: 202.979\n",
      "Current error  234.4718695047214\n",
      "Training until validation scores don't improve for 300 rounds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-8b43fde523a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mcols_effect_mult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;31m#         del df_1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#         gc.collect()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-125-813dfde9035c>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(test_df, train_df, test_target)\u001b[0m\n\u001b[0;32m     61\u001b[0m                         )\n\u001b[0;32m     62\u001b[0m             clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n\u001b[1;32m---> 63\u001b[1;33m                              eval_metric='rmse', verbose= 15000, early_stopping_rounds= 300)\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0moof_preds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda4\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    632\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m                                        \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m                                        callbacks=callbacks)\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda4\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    472\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda4\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    202\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda4\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1526\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1527\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1528\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1529\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1530\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cols_effect_mult = {}\n",
    "col_names = important_features[:10]\n",
    "\n",
    "test_df, train_df, test_target = get_df(1)\n",
    "avg_score, pred = test(test_df, train_df, test_target)\n",
    "cols_effect_mult['baseline'] = avg_score\n",
    "\n",
    "\n",
    "for idx in range(len(col_names)):\n",
    "    for idx2 in range(idx+1, len(col_names)):\n",
    "        test_df, train_df, test_target = get_df(1)\n",
    "        col = col_names[idx]+'-*-'+col_names[idx2]\n",
    "        test_df[col] = test_df[col_names[idx]]*test_df[col_names[idx2]]\n",
    "        train_df[col] = train_df[col_names[idx]]*train_df[col_names[idx2]]\n",
    "        cols_effect_mult[col] = test(test_df, train_df, test_target)\n",
    "#         del df_1\n",
    "#         gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 18)\n",
      "\n",
      "Starting LightGBM. Train shape: (6990, 81), test shape: (1736, 82)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4703]\ttraining's rmse: 72.8514\tvalid_1's rmse: 230.15\n",
      "Current error  238.08681647499262\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2959]\ttraining's rmse: 96.1656\tvalid_1's rmse: 218.827\n",
      "Current error  235.82118819870445\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3366]\ttraining's rmse: 91.4307\tvalid_1's rmse: 199.65\n",
      "Current error  236.32159036366477\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[10537]\ttraining's rmse: 37.6169\tvalid_1's rmse: 212.527\n",
      "Current error  240.84589505563883\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3534]\ttraining's rmse: 88.5249\tvalid_1's rmse: 181.554\n",
      "Current error  238.78768307693898\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1146]\ttraining's rmse: 140.377\tvalid_1's rmse: 198.849\n",
      "Current error  237.12042074424758\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5099]\ttraining's rmse: 68.4456\tvalid_1's rmse: 229.796\n",
      "Current error  233.48045139795244\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2748]\ttraining's rmse: 100.704\tvalid_1's rmse: 197.836\n",
      "Current error  234.91342999196397\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4939]\ttraining's rmse: 71.4315\tvalid_1's rmse: 208.181\n",
      "Current error  232.57595002854902\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3925]\ttraining's rmse: 82.6637\tvalid_1's rmse: 249.767\n",
      "Current error  238.93585843298095\n",
      "212.71367610788224\n",
      "232.5923643382764\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df, train_df, test_target = get_df(1)\n",
    "avg_score, pred = test(test_df, train_df, test_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price-*-mean_sq*price\n",
      "price-*-Станций метро от кольца*price\n",
      "mean_sq*price-*-Станций метро от кольца*price\n"
     ]
    }
   ],
   "source": [
    "for key, value in cols_effect_mult.items():\n",
    "    if (key != 'baseline') and (value[0] < 233.78) and (value[1] < pred):\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(input_dir,'train.csv'), parse_dates=['date1'])\n",
    "df['new_index_spalen'] = df['bulk_id'] + '-' + df['spalen'].astype(str)\n",
    "temp = pd.pivot_table(df, index='new_index_spalen', values=[\"price\"], columns=\"month_cnt\", aggfunc=np.mean)\n",
    "# temp = df.pivot(index='new_index_spalen', values=[\"price\"], columns=\"month_cnt\")\n",
    "temp.columns = [\"value_lag_{}\".format(i)  if j[1] != \"\" else j[0] for i, j in enumerate(temp.columns)]\n",
    "df = df.merge(temp, left_index=True, right_index=True,  how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FLATS_date_salestart_month_VAR',\n",
       " 'FLATS_date_salestart_week_VAR',\n",
       " 'FLATS_otdelka_Ветка сакуры (под покраску)_MAX',\n",
       " 'FLATS_otdelka_Ветка сакуры (под покраску)_MEAN',\n",
       " 'FLATS_otdelka_Ветка сакуры (под покраску)_SUM',\n",
       " 'FLATS_otdelka_Ветка сакуры_MAX',\n",
       " 'FLATS_otdelka_Ветка сакуры_MEAN',\n",
       " 'FLATS_otdelka_Вишневый сад_MAX',\n",
       " 'FLATS_otdelka_Вишневый сад_SUM',\n",
       " 'FLATS_otdelka_Вишнёвый сад (под покраску)_MAX',\n",
       " 'FLATS_otdelka_Вишнёвый сад (под покраску)_MEAN',\n",
       " 'FLATS_otdelka_Вишнёвый сад (под покраску)_SUM',\n",
       " 'FLATS_otdelka_Индивидуальная отделка Мортон_SUM',\n",
       " 'FLATS_otdelka_Комфорт_MAX',\n",
       " 'FLATS_otdelka_Комфорт_MEAN',\n",
       " 'FLATS_otdelka_Комфорт_SUM',\n",
       " 'FLATS_otdelka_Не производится (с кондиционером)_MAX',\n",
       " 'FLATS_otdelka_ОПТИМА ДСК2_MAX',\n",
       " 'FLATS_otdelka_ОПТИМА ДСК3_MAX',\n",
       " 'FLATS_otdelka_ОПТИМА ДСК3_MEAN',\n",
       " 'FLATS_otdelka_ОПТИМА ДСК3_SUM',\n",
       " 'FLATS_otdelka_Подготовка (под чистовую)_MAX',\n",
       " 'FLATS_otdelka_СТАНДАРТ ДСК2_MAX',\n",
       " 'FLATS_otdelka_СТАНДАРТ ДСК2_MEAN',\n",
       " 'FLATS_otdelka_СТАНДАРТ ДСК2_SUM',\n",
       " 'FLATS_plan_size_L_MAX',\n",
       " 'FLATS_plan_size_nan_MAX',\n",
       " 'FLATS_plan_size_nan_MEAN',\n",
       " 'FLATS_plan_size_nan_SUM',\n",
       " 'FLATS_stage_number_MIN',\n",
       " 'FLATS_vid_ двор_MAX',\n",
       " 'FLATS_vid_ двор_MEAN',\n",
       " 'FLATS_vid_ двор_SUM',\n",
       " 'bulk_id_3_4969',\n",
       " 'bulk_id_3_4B39',\n",
       " 'bulk_id_5_0050568859FB',\n",
       " 'bulk_id_5_5DC1C531D3F2',\n",
       " 'bulk_id_5_6833EE54BC25',\n",
       " 'Входные группы_да',\n",
       " 'Входные группы_нет',\n",
       " 'Лифт',\n",
       " 'Система мусоротведения_контейнеры',\n",
       " 'Спортивная площадка_да']"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df.groupby('feature').agg({'importance':'mean'}).sort_values('importance', ascending = False)\n",
    "not_important_features = feature_importance_df.groupby('feature').agg({'importance':'mean'})\n",
    "not_important_features = not_important_features[not_important_features['importance'] == 0].index.tolist()\n",
    "not_important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['price',\n",
       " 'mean_sq_spalen',\n",
       " 'mean_sq*price',\n",
       " 'Станций метро от кольца*price',\n",
       " 'Вклады свыше 3 лет',\n",
       " 'mean_fl',\n",
       " 'spalen*month_cnt',\n",
       " 'mean_sq',\n",
       " 'id',\n",
       " 'Cтавка по ипотеке',\n",
       " 'FLATS_sp_spalen_SUM',\n",
       " 'FLATS_sp_square_SUM',\n",
       " 'month',\n",
       " 'Вклады до 1 года',\n",
       " 'FLATS_sp_spalen_COUNT',\n",
       " 'Вклады от 1 года до 3 лет',\n",
       " 'FLATS_sp_stage_number_MEAN',\n",
       " 'Площадь двора',\n",
       " 'До большой дороги на машине(км)',\n",
       " 'spalen*Площадь зеленой зоны в радиусе 500 м',\n",
       " 'До парка(км)',\n",
       " 'month_cnt',\n",
       " 'Площадь зеленой зоны в радиусе 500 м',\n",
       " 'До метро пешком(км)',\n",
       " 'До промки(км)',\n",
       " 'FLATS_sp_square_MEAN',\n",
       " 'До удобной авторазвязки на машине(км)',\n",
       " 'До парка пешком(км)',\n",
       " 'Площадь пром. зоны в радиусе 500 м',\n",
       " 'FLATS_sp_stage_number_MAX',\n",
       " 'Количество помещений',\n",
       " 'Машиномест',\n",
       " 'Площадь земельного участка',\n",
       " 'Детский сад',\n",
       " 'Школа',\n",
       " 'До Кремля',\n",
       " 'Станций метро от кольца',\n",
       " 'До Садового(км)',\n",
       " 'Вентлияция',\n",
       " 'Поликлиника',\n",
       " 'Двор без машин_нет',\n",
       " 'До ТТК(км)',\n",
       " 'Подземная парковка_да',\n",
       " 'Кладовые_нет',\n",
       " 'Кондиционирование',\n",
       " 'Автомойка_да',\n",
       " 'Видеонаблюдение',\n",
       " 'Класс объекта_комфорт',\n",
       " 'Колясочные_нет',\n",
       " 'Класс объекта_стандарт',\n",
       " 'spalen',\n",
       " 'Двор без машин_да',\n",
       " 'Класс объекта_эконом',\n",
       " 'Подземная парковка_нет',\n",
       " 'Автомойка_нет',\n",
       " 'ФОК',\n",
       " 'Кладовые_да',\n",
       " 'Колясочные_да',\n",
       " 'Огорожена территория_нет',\n",
       " 'Входные группы_нет',\n",
       " 'Огорожена территория_да',\n",
       " 'Входные группы_да']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df.groupby('feature').agg({'importance':'mean'}).sort_values('importance', ascending = False)\n",
    "important_features = feature_importance_df.groupby('feature').agg({'importance':'mean'})\n",
    "important_features = important_features[important_features['importance'] >= 0].sort_values('importance', ascending = False).index.tolist()\n",
    "important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(input_dir,'train.csv'), parse_dates=['date1'])\n",
    "df['index_bulk_id_spalen'] = df['bulk_id'] + '-' + df['spalen'].astype(str)\n",
    "df['mean_sq_spalen'] = df['mean_sq'] / (df['spalen']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_col = 'index_bulk_id_spalen'\n",
    "aggregations = {}\n",
    "\n",
    "aggregations = {\n",
    "                'value': ['max'],\n",
    "            }\n",
    "df_agg = df.groupby([groupby_col]).agg(aggregations)\n",
    "df_agg.columns = pd.Index(['AGG_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "df = df.join(df_agg, how='left', on=groupby_col, rsuffix='_'+groupby_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulk_cols = ['bulk_id_1','bulk_id_2','bulk_id_3','bulk_id_4','bulk_id_5']\n",
    "df_bulk = pd.DataFrame(df.bulk_id.str.split('-').values.tolist(), columns=df_bulk_cols\n",
    "                       , index=df.index)\n",
    "df[df_bulk_cols] = df_bulk[df_bulk_cols]\n",
    "col1 = 'bulk_id_5'\n",
    "col2 = 'spalen'\n",
    "col3 = 'month'\n",
    "index_name = 'index_'+col1+'_'+col2+'_'+col3\n",
    "df[index_name] = df[col1] + '-' + df[col2].astype(str) + '-' + df[col3].astype(str)\n",
    "groupby_col = index_name\n",
    "aggregations = {\n",
    "            'value': ['mean'],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv', encoding='cp1251', decimal=',', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
