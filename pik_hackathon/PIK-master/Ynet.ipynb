{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from preprocess import preprocess_train, preprocess, FEATURES, CATEGORICAL_FEATURES, TEST_FEATURES, CATEGORICAL_TEST_FEATURES_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X, y = preprocess_train(train, categotical_features=CATEGORICAL_FEATURES, features=TEST_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y)\n",
    "y = y[:, None]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8716, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Feature preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def encode_categorical(X, cat_feat):\n",
    "    '''\n",
    "    Encodes categorical features with one-hot encoding and adds it into model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: numpy.ndarray\n",
    "        Training features\n",
    "    cat_feat: list of int\n",
    "        Categorical features indices\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tweaked_X: numpy.ndarray\n",
    "        Tweaked X\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # All the rest\n",
    "    rest = np.ones(X.shape[1], np.bool)\n",
    "    rest[cat_feat] = False\n",
    "    \n",
    "    X_rest = X[:, rest]\n",
    "    \n",
    "    # Encoded\n",
    "    one_hot_encoded = []\n",
    "    \n",
    "    for col_idx in cat_feat:  \n",
    "        encoded = label_binarize(X[:, col_idx], np.unique(X[:, col_idx]).astype(int))\n",
    "        \n",
    "        #print encoded.shape\n",
    "        \n",
    "        one_hot_encoded.append(\n",
    "            encoded\n",
    "        )\n",
    "    \n",
    "    one_hot_encoded.append(X_rest)\n",
    "    \n",
    "    return np.hstack(one_hot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "encoded_X = encode_categorical(X, CATEGORICAL_TEST_FEATURES_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "encoded_X = scaler.fit_transform(encoded_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8716, 44) (8716, 46)\n"
     ]
    }
   ],
   "source": [
    "print X.shape, encoded_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batch_iterator(X, y, batch_size):\n",
    "    for i in range(0, len(X) - batch_size, batch_size):\n",
    "        yield X[i:i+batch_size], y[i:i+batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Ynet4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### CrossVal mean scores\n",
    "* catboost_d10: 224.01548277848525\n",
    "* catboost_d16: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Training simple model\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 1000\n",
    "LEARNING_RATE=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 25 Loss:314.149505615 Val loss: 340.738677979\n",
      "Epoch 50 Loss:287.370697021 Val loss: 317.534088135\n",
      "Epoch 75 Loss:275.498962402 Val loss: 309.536956787\n",
      "Epoch 100 Loss:267.550140381 Val loss: 304.236724854\n",
      "Epoch 125 Loss:260.264801025 Val loss: 299.75112915\n",
      "Epoch 150 Loss:253.576538086 Val loss: 296.292510986\n",
      "Epoch 175 Loss:247.419265747 Val loss: 293.496368408\n",
      "Epoch 200 Loss:241.627487183 Val loss: 291.108856201\n",
      "Epoch 225 Loss:235.946426392 Val loss: 289.057373047\n",
      "Epoch 250 Loss:230.761474609 Val loss: 287.2605896\n",
      "Epoch 275 Loss:226.099151611 Val loss: 285.719665527\n",
      "Epoch 300 Loss:221.905426025 Val loss: 284.526123047\n",
      "Epoch 325 Loss:218.067077637 Val loss: 283.495605469\n",
      "Epoch 350 Loss:214.459060669 Val loss: 282.548126221\n",
      "Epoch 375 Loss:211.055526733 Val loss: 281.543731689\n",
      "Epoch 400 Loss:207.642318726 Val loss: 280.653747559\n",
      "Epoch 425 Loss:204.280700684 Val loss: 280.069580078\n",
      "Epoch 450 Loss:200.874588013 Val loss: 278.985717773\n",
      "Epoch 475 Loss:197.576934814 Val loss: 278.329406738\n",
      "Epoch 500 Loss:194.401245117 Val loss: 277.958587646\n",
      "Epoch 525 Loss:191.238189697 Val loss: 277.285736084\n",
      "Epoch 550 Loss:188.260772705 Val loss: 276.984832764\n",
      "Epoch 575 Loss:185.583267212 Val loss: 276.665344238\n",
      "Epoch 600 Loss:183.089065552 Val loss: 276.580413818\n",
      "Epoch 625 Loss:180.741867065 Val loss: 276.635925293\n",
      "Epoch 650 Loss:178.641815186 Val loss: 276.58291626\n",
      "Epoch 675 Loss:176.735214233 Val loss: 276.554504395\n",
      "Epoch 700 Loss:174.916793823 Val loss: 276.594818115\n",
      "Epoch 725 Loss:173.183639526 Val loss: 276.745178223\n",
      "Epoch 750 Loss:171.489517212 Val loss: 276.86895752\n",
      "Epoch 775 Loss:169.856994629 Val loss: 276.921112061\n",
      "Epoch 800 Loss:168.316101074 Val loss: 277.156951904\n",
      "Epoch 825 Loss:166.949874878 Val loss: 277.402679443\n",
      "Epoch 850 Loss:165.691177368 Val loss: 277.762939453\n",
      "Epoch 875 Loss:164.521026611 Val loss: 278.248382568\n",
      "Epoch 900 Loss:163.384506226 Val loss: 278.623504639\n",
      "Epoch 925 Loss:162.269851685 Val loss: 278.748474121\n",
      "Epoch 950 Loss:161.172195435 Val loss: 278.779907227\n",
      "Epoch 975 Loss:160.068847656 Val loss: 278.793029785\n",
      "Epoch 1000 Loss:159.045883179 Val loss: 278.822052002\n",
      "After 5 folds: 277.210113525\n",
      "Fold 2\n",
      "Epoch 25 Loss:306.361602783 Val loss: 318.379425049\n",
      "Epoch 50 Loss:281.768218994 Val loss: 300.851501465\n",
      "Epoch 75 Loss:270.105621338 Val loss: 293.980682373\n",
      "Epoch 100 Loss:261.818328857 Val loss: 289.912750244\n",
      "Epoch 125 Loss:254.808059692 Val loss: 286.777709961\n",
      "Epoch 150 Loss:248.61378479 Val loss: 284.373382568\n",
      "Epoch 175 Loss:243.063735962 Val loss: 282.558502197\n",
      "Epoch 200 Loss:238.020309448 Val loss: 280.70223999\n",
      "Epoch 225 Loss:233.377731323 Val loss: 279.268127441\n",
      "Epoch 250 Loss:229.115158081 Val loss: 278.0078125\n",
      "Epoch 275 Loss:225.166275024 Val loss: 276.897247314\n",
      "Epoch 300 Loss:221.382446289 Val loss: 276.019378662\n",
      "Epoch 325 Loss:217.7293396 Val loss: 274.834564209\n",
      "Epoch 350 Loss:214.188079834 Val loss: 273.490509033\n",
      "Epoch 375 Loss:210.682144165 Val loss: 272.059020996\n",
      "Epoch 400 Loss:207.432022095 Val loss: 271.33416748\n",
      "Epoch 425 Loss:204.382385254 Val loss: 270.848022461\n",
      "Epoch 450 Loss:201.483825684 Val loss: 270.767120361\n",
      "Epoch 475 Loss:198.786453247 Val loss: 270.542358398\n",
      "Epoch 500 Loss:196.373779297 Val loss: 270.622497559\n",
      "Epoch 525 Loss:194.088912964 Val loss: 270.912200928\n",
      "Epoch 550 Loss:192.019744873 Val loss: 271.382263184\n",
      "Epoch 575 Loss:190.019363403 Val loss: 271.933746338\n",
      "Epoch 600 Loss:188.11239624 Val loss: 272.490692139\n",
      "Epoch 625 Loss:186.355667114 Val loss: 272.909393311\n",
      "Epoch 650 Loss:184.702377319 Val loss: 273.197021484\n",
      "Epoch 675 Loss:183.119613647 Val loss: 273.389007568\n",
      "Epoch 700 Loss:181.530303955 Val loss: 273.69229126\n",
      "Epoch 725 Loss:179.909957886 Val loss: 274.126525879\n",
      "Epoch 750 Loss:178.404815674 Val loss: 274.54019165\n",
      "Epoch 775 Loss:176.992019653 Val loss: 274.833435059\n",
      "Epoch 800 Loss:175.599273682 Val loss: 275.134643555\n",
      "Epoch 825 Loss:174.200759888 Val loss: 275.475891113\n",
      "Epoch 850 Loss:172.836212158 Val loss: 275.983612061\n",
      "Epoch 875 Loss:171.541381836 Val loss: 276.404052734\n",
      "Epoch 900 Loss:170.345230103 Val loss: 276.873901367\n",
      "Epoch 925 Loss:169.167785645 Val loss: 277.253967285\n",
      "Epoch 950 Loss:167.993713379 Val loss: 277.821594238\n",
      "Epoch 975 Loss:166.888534546 Val loss: 278.546508789\n",
      "Epoch 1000 Loss:165.834442139 Val loss: 279.354217529\n",
      "After 5 folds: 264.355224609\n",
      "Fold 3\n",
      "Epoch 25 Loss:320.870391846 Val loss: 328.141204834\n",
      "Epoch 50 Loss:293.997009277 Val loss: 305.858154297\n",
      "Epoch 75 Loss:278.976989746 Val loss: 298.35949707\n",
      "Epoch 100 Loss:269.524078369 Val loss: 295.846008301\n",
      "Epoch 125 Loss:261.936401367 Val loss: 294.962493896\n",
      "Epoch 150 Loss:254.656738281 Val loss: 294.877746582\n",
      "Epoch 175 Loss:247.53868103 Val loss: 295.161712646\n",
      "Epoch 200 Loss:240.770706177 Val loss: 295.632385254\n",
      "Epoch 225 Loss:234.319244385 Val loss: 296.415008545\n",
      "Epoch 250 Loss:227.970962524 Val loss: 296.954467773\n",
      "Epoch 275 Loss:221.783111572 Val loss: 297.589263916\n",
      "Epoch 300 Loss:216.195114136 Val loss: 298.524017334\n",
      "Epoch 325 Loss:211.116149902 Val loss: 299.345550537\n",
      "Epoch 350 Loss:206.607955933 Val loss: 300.124572754\n",
      "Epoch 375 Loss:202.401046753 Val loss: 300.87387085\n",
      "Epoch 400 Loss:198.464614868 Val loss: 301.571411133\n",
      "Epoch 425 Loss:194.608810425 Val loss: 302.652679443\n",
      "Epoch 450 Loss:191.065093994 Val loss: 303.934387207\n",
      "Epoch 475 Loss:187.777755737 Val loss: 305.578674316\n",
      "Epoch 500 Loss:184.624679565 Val loss: 306.63885498\n",
      "Epoch 525 Loss:181.64251709 Val loss: 307.383880615\n",
      "Epoch 550 Loss:178.914535522 Val loss: 308.171234131\n",
      "Epoch 575 Loss:176.261886597 Val loss: 309.406188965\n",
      "Epoch 600 Loss:173.681365967 Val loss: 310.694671631\n",
      "Epoch 625 Loss:171.371627808 Val loss: 311.928405762\n",
      "Epoch 650 Loss:169.090255737 Val loss: 313.251190186\n",
      "Epoch 675 Loss:166.776977539 Val loss: 313.859863281\n",
      "Epoch 700 Loss:164.580337524 Val loss: 314.874725342\n",
      "Epoch 725 Loss:162.445358276 Val loss: 314.874420166\n",
      "Epoch 750 Loss:160.355728149 Val loss: 314.79385376\n",
      "Epoch 775 Loss:158.283050537 Val loss: 315.464233398\n",
      "Epoch 800 Loss:156.341796875 Val loss: 315.582763672\n",
      "Epoch 825 Loss:154.510299683 Val loss: 315.641021729\n",
      "Epoch 850 Loss:152.794723511 Val loss: 316.804504395\n",
      "Epoch 875 Loss:151.08605957 Val loss: 317.124328613\n",
      "Epoch 900 Loss:149.411178589 Val loss: 318.357391357\n",
      "Epoch 925 Loss:147.817352295 Val loss: 318.076049805\n",
      "Epoch 950 Loss:146.121414185 Val loss: 319.794464111\n",
      "Epoch 975 Loss:144.536193848 Val loss: 320.199157715\n",
      "Epoch 1000 Loss:142.933502197 Val loss: 321.757904053\n",
      "After 5 folds: 293.077941895\n",
      "Fold 4\n",
      "Epoch 25 Loss:308.995361328 Val loss: 319.031158447\n",
      "Epoch 50 Loss:284.265319824 Val loss: 296.558166504\n",
      "Epoch 75 Loss:274.275634766 Val loss: 287.833007812\n",
      "Epoch 100 Loss:267.453948975 Val loss: 282.9375\n",
      "Epoch 125 Loss:261.857299805 Val loss: 280.019073486\n",
      "Epoch 150 Loss:256.9921875 Val loss: 277.55947876\n",
      "Epoch 175 Loss:252.62727356 Val loss: 275.531280518\n",
      "Epoch 200 Loss:248.401672363 Val loss: 273.817901611\n",
      "Epoch 225 Loss:244.304260254 Val loss: 272.473602295\n",
      "Epoch 250 Loss:240.324142456 Val loss: 271.156463623\n",
      "Epoch 275 Loss:236.278411865 Val loss: 270.004547119\n",
      "Epoch 300 Loss:232.288925171 Val loss: 268.929931641\n",
      "Epoch 325 Loss:228.278930664 Val loss: 268.119232178\n",
      "Epoch 350 Loss:224.322875977 Val loss: 267.773468018\n",
      "Epoch 375 Loss:220.508148193 Val loss: 268.027679443\n",
      "Epoch 400 Loss:216.848724365 Val loss: 268.583343506\n",
      "Epoch 425 Loss:213.331710815 Val loss: 269.380401611\n",
      "Epoch 450 Loss:209.998428345 Val loss: 270.203216553\n",
      "Epoch 475 Loss:206.817871094 Val loss: 271.120513916\n",
      "Epoch 500 Loss:203.707565308 Val loss: 272.158966064\n",
      "Epoch 525 Loss:200.802597046 Val loss: 273.202545166\n",
      "Epoch 550 Loss:198.082229614 Val loss: 274.112609863\n",
      "Epoch 575 Loss:195.491287231 Val loss: 274.750915527\n",
      "Epoch 600 Loss:193.032470703 Val loss: 275.329284668\n",
      "Epoch 625 Loss:190.671554565 Val loss: 275.720245361\n",
      "Epoch 650 Loss:188.308395386 Val loss: 276.264190674\n",
      "Epoch 675 Loss:186.004867554 Val loss: 276.780883789\n",
      "Epoch 700 Loss:183.825836182 Val loss: 277.301605225\n",
      "Epoch 725 Loss:181.795059204 Val loss: 277.929107666\n",
      "Epoch 750 Loss:179.878936768 Val loss: 278.732116699\n",
      "Epoch 775 Loss:178.112319946 Val loss: 279.491699219\n",
      "Epoch 800 Loss:176.376571655 Val loss: 280.155609131\n",
      "Epoch 825 Loss:174.690002441 Val loss: 280.829956055\n",
      "Epoch 850 Loss:173.055511475 Val loss: 281.390045166\n",
      "Epoch 875 Loss:171.442443848 Val loss: 281.914123535\n",
      "Epoch 900 Loss:169.947753906 Val loss: 282.509521484\n",
      "Epoch 925 Loss:168.532241821 Val loss: 282.97479248\n",
      "Epoch 950 Loss:167.170959473 Val loss: 283.393585205\n",
      "Epoch 975 Loss:165.846221924 Val loss: 283.920288086\n",
      "Epoch 1000 Loss:164.602432251 Val loss: 284.531921387\n",
      "After 5 folds: 273.716674805\n",
      "Fold 5\n",
      "Epoch 25 Loss:325.425842285 Val loss: 346.901855469\n",
      "Epoch 50 Loss:305.27166748 Val loss: 330.76675415\n",
      "Epoch 75 Loss:293.143951416 Val loss: 323.149078369\n",
      "Epoch 100 Loss:283.208190918 Val loss: 315.916534424\n",
      "Epoch 125 Loss:274.066345215 Val loss: 309.283416748\n",
      "Epoch 150 Loss:265.285400391 Val loss: 303.422454834\n",
      "Epoch 175 Loss:257.269439697 Val loss: 299.428771973\n",
      "Epoch 200 Loss:250.21774292 Val loss: 296.824493408\n",
      "Epoch 225 Loss:243.682769775 Val loss: 294.434783936\n",
      "Epoch 250 Loss:237.899932861 Val loss: 292.247497559\n",
      "Epoch 275 Loss:232.618133545 Val loss: 290.361663818\n",
      "Epoch 300 Loss:227.501861572 Val loss: 288.780761719\n",
      "Epoch 325 Loss:222.527877808 Val loss: 287.382354736\n",
      "Epoch 350 Loss:217.937911987 Val loss: 286.400085449\n",
      "Epoch 375 Loss:213.687469482 Val loss: 286.056030273\n",
      "Epoch 400 Loss:209.810287476 Val loss: 285.849884033\n",
      "Epoch 425 Loss:206.266860962 Val loss: 285.601501465\n",
      "Epoch 450 Loss:202.912231445 Val loss: 285.367431641\n",
      "Epoch 475 Loss:199.72366333 Val loss: 285.293701172\n",
      "Epoch 500 Loss:196.801773071 Val loss: 285.53326416\n",
      "Epoch 525 Loss:194.297286987 Val loss: 285.661346436\n",
      "Epoch 550 Loss:191.934860229 Val loss: 285.60055542\n",
      "Epoch 575 Loss:189.706451416 Val loss: 285.660614014\n",
      "Epoch 600 Loss:187.656738281 Val loss: 285.71194458\n",
      "Epoch 625 Loss:185.787597656 Val loss: 285.717407227\n",
      "Epoch 650 Loss:183.944061279 Val loss: 285.305908203\n",
      "Epoch 675 Loss:182.158172607 Val loss: 285.011810303\n",
      "Epoch 700 Loss:180.483505249 Val loss: 284.585723877\n",
      "Epoch 725 Loss:178.897613525 Val loss: 284.105560303\n",
      "Epoch 750 Loss:177.404296875 Val loss: 283.563659668\n",
      "Epoch 775 Loss:176.019302368 Val loss: 283.122680664\n",
      "Epoch 800 Loss:174.644760132 Val loss: 282.748565674\n",
      "Epoch 825 Loss:173.339187622 Val loss: 282.278533936\n",
      "Epoch 850 Loss:172.061691284 Val loss: 281.748657227\n",
      "Epoch 875 Loss:170.856307983 Val loss: 281.191864014\n",
      "Epoch 900 Loss:169.68132019 Val loss: 280.773742676\n",
      "Epoch 925 Loss:168.524215698 Val loss: 280.523681641\n",
      "Epoch 950 Loss:167.41569519 Val loss: 280.393798828\n",
      "Epoch 975 Loss:166.255828857 Val loss: 280.42755127\n",
      "Epoch 1000 Loss:165.059020996 Val loss: 280.354553223\n",
      "After 5 folds: 316.390686035\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "fold_num = 1\n",
    "\n",
    "for train, test in kfold.split(encoded_X):\n",
    "   \n",
    "    print \"Fold {}\".format(fold_num)\n",
    "    \n",
    "    X_train, X_test = encoded_X[train], encoded_X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    \n",
    "    # Create validation datasest\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train)\n",
    "    \n",
    "    # Model\n",
    "    input_var = tf.placeholder(tf.float32, shape=[None, X_train.shape[1]])\n",
    "    gt_var = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "    \n",
    "    model = tf.layers.dense(input_var, 50, activation=tf.nn.elu)\n",
    "    \n",
    "    # Block1\n",
    "    block1 = tf.layers.dense(model, 50, activation=tf.nn.elu)\n",
    "    output1 = tf.layers.dense(block1, 1) \n",
    "    \n",
    "    # Block2\n",
    "    block2 = tf.layers.dense(model, 20, activation=tf.nn.elu)\n",
    "    output2 = tf.layers.dense(block2, 1) \n",
    "    \n",
    "    # Block2\n",
    "    block3 = tf.layers.dense(model, 10, activation=tf.nn.elu)\n",
    "    output3 = tf.layers.dense(block3, 1) \n",
    "    \n",
    "    # Block2\n",
    "    block4 = tf.layers.dense(model, 10, activation=tf.nn.elu)\n",
    "    output4 = tf.layers.dense(block4, 1) \n",
    "    \n",
    "    # Final output\n",
    "    #final_output = tf.reduce_mean([output1, output2, output3, output4], axis=0)\n",
    "    final_output = tf.layers.dense(tf.concat([output1, output2, output3, output4], axis=1), 1)\n",
    "    \n",
    "    # Loss function \n",
    "    loss = tf.reduce_mean(tf.losses.mean_squared_error(gt_var, output1)**.5 ) \\\n",
    "    + tf.reduce_mean(tf.losses.mean_squared_error(gt_var, output2)**.5 ) \\\n",
    "    + tf.reduce_mean(tf.losses.mean_squared_error(gt_var, output3)**.5 ) \\\n",
    "    + tf.reduce_mean(tf.losses.mean_squared_error(gt_var, output3)**.5 ) \\\n",
    "    + tf.reduce_mean(tf.losses.mean_squared_error(gt_var, final_output)**.5 )   \n",
    "    \n",
    "    metric = tf.reduce_mean(tf.losses.mean_squared_error(gt_var, final_output)**.5 )   \n",
    "    \n",
    "    \n",
    "    opt = tf.train.AdamOptimizer().minimize(loss)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "      \n",
    "    results = []    \n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(1, EPOCHS+1):  \n",
    "            epoch_loss = []\n",
    "            for X_batch, y_batch in batch_iterator(X_train, y_train, BATCH_SIZE):\n",
    "                batch_loss, pred, _ = sess.run([metric, final_output, opt], feed_dict={input_var: X_batch, gt_var: y_batch})                      \n",
    "                epoch_loss.append(batch_loss)                                \n",
    "             # Validation\n",
    "            val_loss = sess.run(metric, feed_dict={input_var: X_val, gt_var: y_val})\n",
    "            if epoch % 25 == 0:\n",
    "                print \"Epoch {} Loss:{} Val loss: {}\".format(epoch, np.mean(epoch_loss), val_loss)                                \n",
    "        # Testing\n",
    "        fold_test_loss = sess.run(metric, feed_dict={input_var: X_test, gt_var: y_test})\n",
    "\n",
    "        results.append(fold_test_loss)        \n",
    "        \n",
    "        fold_num += 1   \n",
    "    \n",
    "    print \"After 5 folds: {}\".format(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# scorer = make_scorer(lambda a, b: mean_squared_error(a, b)**.5)\n",
    "# scores = cross_val_score(lr, encoded_X, y, cv=5, scoring=scorer, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340.449211318938"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 284.83019248\n"
     ]
    }
   ],
   "source": [
    "y_pred = cbr.fit(X_train, y_train, cat_features=CATEGORICAL_TEST_FEATURES_IDX).predict(X_test)\n",
    "print \"Mean squared error: {}\".format(mean_squared_error(y_test, y_pred)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core._CatBoostBase at 0x7f8a7f594a50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make submission\n",
    "cbr.fit(X, y, cat_features=CATEGORICAL_TEST_FEATURES_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test = preprocess(test, CATEGORICAL_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = test[TEST_FEATURES].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictions = cbr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 879.78794459, 1165.70020084,  279.39788828, ...,  154.47198918,\n",
       "        -62.34725293,   36.55400176])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_submission(ids, predictions):\n",
    "    df = pd.concat([ids, pd.Series(predictions)], axis=1)\n",
    "    return df.rename(columns={0: 'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "l = test.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([test.id, pd.Series(predictions)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={0: 'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"catboost_d10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
